from flask import Flask, render_template, jsonify, request
import threading
import os
import time
import logging
import sys
import re
import glob
from datetime import datetime

# Importa las funciones de database y predicci√≥n (ver abajo)
import database
import predecir_futuro as predecir  # archivo modificado (ver secci√≥n abajo)

app = Flask(__name__)

# Funci√≥n para remover emojis (solo en Windows)
def remove_emojis(text):
    """Remueve emojis del texto para compatibilidad con Windows console"""
    if sys.platform.startswith('win'):
        # Patr√≥n para detectar emojis
        emoji_pattern = re.compile("["
            u"\U0001F600-\U0001F64F"  # emoticons
            u"\U0001F300-\U0001F5FF"  # symbols & pictographs
            u"\U0001F680-\U0001F6FF"  # transport & map symbols
            u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
            u"\U00002702-\U000027B0"
            u"\U000024C2-\U0001F251"
            "]+", flags=re.UNICODE)
        return emoji_pattern.sub('', text)
    return text

# Formatter personalizado para consola (sin emojis en Windows)
class ConsoleFormatter(logging.Formatter):
    def format(self, record):
        original_msg = record.getMessage()
        record.msg = remove_emojis(str(record.msg))
        result = super().format(record)
        record.msg = original_msg  # Restaurar mensaje original
        return result

# Configuraci√≥n de logging
# Handler para archivo (con emojis, UTF-8)
file_handler = logging.FileHandler('app.log', encoding='utf-8')
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))

# Handler para consola (sin emojis, compatible con Windows)
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(ConsoleFormatter('%(asctime)s [%(levelname)s] %(message)s'))

# Configurar logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.addHandler(file_handler)
logger.addHandler(console_handler)

# Variables globales para el hilo de sincronizaci√≥n
sync_thread = None
sync_running = False

# Configuraci√≥n de sincronizaci√≥n (sin variables de entorno)
CSV_PATH = 'Codigos_arduinos/data/sensor_data.csv'
SYNC_INTERVAL = 60  # Sincronizar cada 60 segundos

def sync_csv_to_database():
    """
    Funci√≥n que se ejecuta en segundo plano y sincroniza el CSV con la DB.
    Verifica cada SYNC_INTERVAL segundos si hay datos nuevos en el CSV.
    """
    global sync_running
    logger.info(f"üîÑ Iniciando sincronizaci√≥n autom√°tica de {CSV_PATH} cada {SYNC_INTERVAL}s")
    
    while sync_running:
        try:
            if os.path.exists(CSV_PATH):
                logger.info(f"üì• Sincronizando {CSV_PATH} a la base de datos...")
                rows_added = database.load_csv_and_aggregate_to_db(csv_path=CSV_PATH)
                if rows_added > 0:
                    logger.info(f"‚úÖ Sincronizaci√≥n completada: {rows_added} registros nuevos agregados")
                else:
                    logger.debug(f"‚ÑπÔ∏è  Sin datos nuevos para sincronizar")
            else:
                logger.warning(f"‚ö†Ô∏è  Archivo {CSV_PATH} no encontrado en ruta absoluta: {os.path.abspath(CSV_PATH)}")
        except FileNotFoundError as e:
            logger.error(f"‚ùå Error: Archivo no encontrado - {e}")
        except ValueError as e:
            logger.error(f"‚ùå Error de valor en CSV: {e}")
        except Exception as e:
            logger.error(f"‚ùå Error inesperado en sincronizaci√≥n autom√°tica: {type(e).__name__}: {e}", exc_info=True)
        
        # Esperar antes de la pr√≥xima sincronizaci√≥n
        time.sleep(SYNC_INTERVAL)

def start_auto_sync():
    """Inicia el hilo de sincronizaci√≥n autom√°tica"""
    global sync_thread, sync_running
    
    if sync_running:
        logger.warning("‚ö†Ô∏è  La sincronizaci√≥n autom√°tica ya est√° corriendo")
        return
    
    try:
        sync_running = True
        sync_thread = threading.Thread(
            target=sync_csv_to_database,
            daemon=True  # El hilo se cierra cuando se cierra la app
        )
        sync_thread.start()
        logger.info("üöÄ Sincronizaci√≥n autom√°tica iniciada exitosamente")
    except Exception as e:
        logger.error(f"‚ùå Error al iniciar sincronizaci√≥n autom√°tica: {e}", exc_info=True)
        sync_running = False

def stop_auto_sync():
    """Detiene el hilo de sincronizaci√≥n autom√°tica"""
    global sync_running
    sync_running = False
    logger.info("üõë Sincronizaci√≥n autom√°tica detenida")

# Inicializa DB al arrancar
try:
    logger.info("üóÑÔ∏è  Inicializando base de datos...")
    database.init_database()
    logger.info("‚úÖ Base de datos inicializada correctamente")
except Exception as e:
    logger.error(f"‚ùå Error al inicializar base de datos: {e}", exc_info=True)

# Inicia sincronizaci√≥n autom√°tica al arrancar la app
try:
    start_auto_sync()
except Exception as e:
    logger.error(f"‚ùå Error cr√≠tico al iniciar la aplicaci√≥n: {e}", exc_info=True)

@app.route('/')
def index():
    try:
        logger.debug("üìÑ Cargando p√°gina principal")
        return render_template('index.html')
    except Exception as e:
        logger.error(f"‚ùå Error al cargar p√°gina principal: {e}", exc_info=True)
        return jsonify({"status": "error", "message": "Error al cargar la p√°gina"}), 500

# Endpoint para obtener √∫ltimos N registros (sensor_data)
@app.route('/api/sensor/latest', methods=['GET'])
def api_latest_sensor():
    try:
        limit = int(request.args.get('limit', 10))
        logger.debug(f"üìä Consultando √∫ltimos {limit} registros del sensor")
        data = database.get_latest_sensor_data(limit=limit)
        logger.debug(f"‚úÖ Retornando {len(data)} registros")
        return jsonify(data)
    except ValueError as e:
        logger.error(f"‚ùå Error de valor en par√°metro limit: {e}")
        return jsonify({"status": "error", "message": "Par√°metro 'limit' inv√°lido"}), 400
    except Exception as e:
        logger.error(f"‚ùå Error al obtener datos del sensor: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

# Endpoint para obtener predicciones futuras (todas o limitadas)
@app.route('/api/predictions/future', methods=['GET'])
def api_future_predictions():
    try:
        limit = int(request.args.get('limit', 0))
        logger.debug(f"üîÆ Consultando predicciones futuras (limit={limit})")
        preds = database.get_future_predictions()
        if limit and isinstance(limit, int):
            preds = preds[:limit]
        logger.debug(f"‚úÖ Retornando {len(preds)} predicciones")
        return jsonify(preds)
    except ValueError as e:
        logger.error(f"‚ùå Error de valor en par√°metro limit: {e}")
        return jsonify({"status": "error", "message": "Par√°metro 'limit' inv√°lido"}), 400
    except Exception as e:
        logger.error(f"‚ùå Error al obtener predicciones: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

# Endpoint para forzar carga del CSV y agregaci√≥n por minuto
@app.route('/api/load_csv', methods=['POST'])
def api_load_csv():
    """
    POST /api/load_csv
    Body JSON opcional: {"csv_path": "/ruta/a/sensor_data.csv"}
    """
    try:
        payload = request.get_json(silent=True) or {}
        csv_path = payload.get('csv_path')
        logger.info(f"üì• Carga manual de CSV solicitada: {csv_path or CSV_PATH}")
        rows_added = database.load_csv_and_aggregate_to_db(csv_path=csv_path)
        logger.info(f"‚úÖ CSV cargado exitosamente: {rows_added} registros agregados")
        return jsonify({
            "status": "ok", 
            "message": "CSV cargado y agregado por minuto a la DB",
            "rows_added": rows_added
        }), 200
    except FileNotFoundError as e:
        logger.error(f"‚ùå Error: Archivo CSV no encontrado - {e}")
        return jsonify({"status": "error", "message": f"Archivo no encontrado: {e}"}), 404
    except ValueError as e:
        logger.error(f"‚ùå Error de valor en CSV: {e}")
        return jsonify({"status": "error", "message": f"Error en formato de CSV: {e}"}), 400
    except Exception as e:
        logger.error(f"‚ùå Error al cargar CSV: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

# Endpoint para ejecutar predicci√≥n (bloqueante); opcional: lanzarlo en hilo
@app.route('/api/predict', methods=['POST'])
def api_predict():
    """
    POST /api/predict
    Body JSON: {"horas_futuro": 6, "model_path": null}
    """
    try:
        payload = request.get_json(silent=True) or {}
        horas = int(payload.get('horas_futuro', 6))
        logger.info(f"üîÆ Predicci√≥n solicitada para {horas} horas futuras")

        # Variable compartida para capturar errores
        prediction_result = {"status": "running", "error": None}

        # Ejecutar la predicci√≥n en un hilo para no bloquear (puedes cambiar si quieres bloqueante)
        def run_prediction():
            try:
                logger.info(f"üöÄ Iniciando proceso de predicci√≥n...")
                
                # 1. Limpiar predicciones antiguas de la base de datos
                deleted = database.clear_predictions()
                logger.info(f"üóëÔ∏è  Predicciones antiguas eliminadas de BD: {deleted} registros")
                
                # 2. Eliminar CSVs antiguos de predicciones
                old_csvs = glob.glob('predicciones_*_horas_por_minuto.csv')
                for old_csv in old_csvs:
                    try:
                        os.remove(old_csv)
                        logger.info(f"üóëÔ∏è  CSV antiguo eliminado: {old_csv}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è  No se pudo eliminar {old_csv}: {e}")
                
                # 3. Generar nuevas predicciones
                output_csv = predecir.run_prediction(horas_futuro=horas)
                logger.info(f"üìä Predicci√≥n completada, guardando en DB desde {output_csv}")
                # leer CSV y guardar en DB
                database.insert_predictions_from_csv(output_csv)
                prediction_result["status"] = "success"
                logger.info(f"‚úÖ Predicciones guardadas exitosamente en la base de datos")
            except FileNotFoundError as e:
                logger.error(f"‚ùå Error: Archivo de predicci√≥n no encontrado - {e}")
                prediction_result["status"] = "error"
                prediction_result["error"] = f"Archivo no encontrado: {e}"
            except Exception as e:
                logger.error(f"‚ùå Error en proceso de predicci√≥n: {type(e).__name__}: {e}", exc_info=True)
                prediction_result["status"] = "error"
                prediction_result["error"] = str(e)

        thread = threading.Thread(target=run_prediction)
        thread.start()

        return jsonify({"status": "running", "message": f"Predicci√≥n por {horas} horas iniciada en background."}), 202
    except ValueError as e:
        logger.error(f"‚ùå Error de valor en par√°metros de predicci√≥n: {e}")
        return jsonify({"status": "error", "message": "Par√°metros inv√°lidos"}), 400
    except Exception as e:
        logger.error(f"‚ùå Error al iniciar predicci√≥n: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

# Endpoint para verificar el estado de la √∫ltima predicci√≥n
@app.route('/api/predict/status', methods=['GET'])
def api_predict_status():
    """
    GET /api/predict/status
    Devuelve si hay predicciones en la base de datos
    """
    try:
        preds = database.get_future_predictions()
        if preds and len(preds) > 0:
            return jsonify({"status": "success", "count": len(preds)}), 200
        else:
            return jsonify({"status": "no_data", "count": 0}), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

# Endpoints para controlar la sincronizaci√≥n autom√°tica
@app.route('/api/sync/status', methods=['GET'])
def api_sync_status():
    """
    GET /api/sync/status
    Devuelve el estado de la sincronizaci√≥n autom√°tica
    """
    try:
        logger.debug("üîç Consultando estado de sincronizaci√≥n")
        status = {
            "running": sync_running,
            "csv_path": CSV_PATH,
            "csv_path_absolute": os.path.abspath(CSV_PATH),
            "csv_exists": os.path.exists(CSV_PATH),
            "interval_seconds": SYNC_INTERVAL
        }
        return jsonify(status), 200
    except Exception as e:
        logger.error(f"‚ùå Error al consultar estado de sincronizaci√≥n: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/sync/start', methods=['POST'])
def api_start_sync():
    """
    POST /api/sync/start
    Inicia la sincronizaci√≥n autom√°tica (si est√° detenida)
    """
    try:
        logger.info("‚ñ∂Ô∏è  Solicitud de iniciar sincronizaci√≥n autom√°tica")
        start_auto_sync()
        return jsonify({"status": "ok", "message": "Sincronizaci√≥n iniciada"}), 200
    except Exception as e:
        logger.error(f"‚ùå Error al iniciar sincronizaci√≥n: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/sync/stop', methods=['POST'])
def api_stop_sync():
    """
    POST /api/sync/stop
    Detiene la sincronizaci√≥n autom√°tica
    """
    try:
        logger.info("‚è∏Ô∏è  Solicitud de detener sincronizaci√≥n autom√°tica")
        stop_auto_sync()
        return jsonify({"status": "ok", "message": "Sincronizaci√≥n detenida"}), 200
    except Exception as e:
        logger.error(f"‚ùå Error al detener sincronizaci√≥n: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/sync/force', methods=['POST'])
def api_force_sync():
    """
    POST /api/sync/force
    Fuerza una sincronizaci√≥n inmediata (sin esperar el intervalo)
    """
    try:
        logger.info(f"‚ö° Sincronizaci√≥n forzada solicitada para {CSV_PATH}")
        if os.path.exists(CSV_PATH):
            rows_added = database.load_csv_and_aggregate_to_db(csv_path=CSV_PATH)
            logger.info(f"‚úÖ Sincronizaci√≥n forzada completada: {rows_added} registros agregados")
            return jsonify({
                "status": "ok", 
                "message": f"Sincronizaci√≥n forzada completada", 
                "rows_added": rows_added
            }), 200
        else:
            logger.warning(f"‚ö†Ô∏è  CSV no encontrado en: {os.path.abspath(CSV_PATH)}")
            return jsonify({
                "status": "error", 
                "message": f"CSV no encontrado en {CSV_PATH}",
                "absolute_path": os.path.abspath(CSV_PATH)
            }), 404
    except FileNotFoundError as e:
        logger.error(f"‚ùå Error: Archivo no encontrado - {e}")
        return jsonify({"status": "error", "message": f"Archivo no encontrado: {e}"}), 404
    except Exception as e:
        logger.error(f"‚ùå Error al forzar sincronizaci√≥n: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

# Endpoint para ver logs recientes
@app.route('/api/logs', methods=['GET'])
def api_logs():
    """
    GET /api/logs?lines=50
    Devuelve las √∫ltimas l√≠neas del archivo de log
    """
    try:
        lines = int(request.args.get('lines', 50))
        log_file = 'app.log'
        
        if not os.path.exists(log_file):
            return jsonify({
                "status": "warning",
                "message": "Archivo de log no existe a√∫n",
                "logs": []
            }), 200
        
        with open(log_file, 'r', encoding='utf-8') as f:
            all_lines = f.readlines()
            recent_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines
        
        return jsonify({
            "status": "ok",
            "total_lines": len(all_lines),
            "returned_lines": len(recent_lines),
            "logs": [line.strip() for line in recent_lines]
        }), 200
    except ValueError as e:
        logger.error(f"‚ùå Error de valor en par√°metro lines: {e}")
        return jsonify({"status": "error", "message": "Par√°metro 'lines' inv√°lido"}), 400
    except Exception as e:
        logger.error(f"‚ùå Error al leer logs: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

if __name__ == '__main__':
    try:
        logger.info("="*60)
        logger.info("üöÄ Iniciando aplicaci√≥n Flask - Sistema de Clima")
        logger.info(f"üìÅ Directorio de trabajo: {os.getcwd()}")
        logger.info(f"üìÑ CSV Path: {os.path.abspath(CSV_PATH)}")
        logger.info(f"‚è±Ô∏è  Intervalo de sincronizaci√≥n: {SYNC_INTERVAL} segundos")
        logger.info("="*60)
        app.run(debug=True, host='0.0.0.0', port=5000)
    except KeyboardInterrupt:
        logger.info("‚ö†Ô∏è  Aplicaci√≥n interrumpida por el usuario (Ctrl+C)")
        stop_auto_sync()
    except Exception as e:
        logger.critical(f"‚ùå Error cr√≠tico al iniciar la aplicaci√≥n: {e}", exc_info=True)
    finally:
        logger.info("üëã Aplicaci√≥n finalizada")
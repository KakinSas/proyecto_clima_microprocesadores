"""
Script para predecir las siguientes 6 horas de temperatura
usando el modelo LSTM entrenado con 3 features (ts, hr, p0).

El script toma los √∫ltimos datos de sensor_data.csv y genera
predicciones iterativas hacia el futuro.
"""

import os
import sys
from pathlib import Path
import numpy as np
import pandas as pd
import warnings
from datetime import datetime, timedelta
import argparse

warnings.filterwarnings("ignore", category=FutureWarning)
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "2")

def main():
    parser = argparse.ArgumentParser(description='Predecir futuro o hacer preprocesado (dry-run)')
    parser.add_argument('--dry-run', action='store_true', help='Solo preprocesar el CSV (resample 1min) y guardar muestra')
    args = parser.parse_args()
    # Rutas
    base_dir = Path(__file__).resolve().parent
    model_path = base_dir / "modelo_lstm_3_features.h5"
    scaler_path = base_dir / "scaler_3_features.pkl"
    csv_path = base_dir.parent / "Codigos_arduinos" / "data" / "sensor_data.csv"
    
    print("=" * 70)
    print("üîÆ PREDICCI√ìN DE TEMPERATURA A FUTURO (6 HORAS)")
    print("=" * 70)
    
    # 1. Verificar archivos
    if args.dry_run:
        # En modo dry-run solo necesitamos el CSV de datos
        if not csv_path.exists():
            print(f"‚ùå CSV no encontrado: {csv_path}")
            sys.exit(1)
        print(f"‚úÖ Datos: {csv_path}")
    else:
        if not model_path.exists():
            print(f"\n‚ùå Modelo no encontrado: {model_path}")
            print(f"\nüí° Por favor, entrena el modelo primero ejecutando:")
            print(f"   Abre y ejecuta: entrenar_modelo_simple.ipynb")
            sys.exit(1)
        
        if not scaler_path.exists():
            print(f"‚ùå Scaler no encontrado: {scaler_path}")
            print(f"\nüí° Por favor, entrena el modelo primero.")
            sys.exit(1)
        
        if not csv_path.exists():
            print(f"‚ùå CSV no encontrado: {csv_path}")
            sys.exit(1)
        
        print(f"‚úÖ Modelo: {model_path.name}")
        print(f"‚úÖ Scaler: {scaler_path.name}")
        print(f"‚úÖ Datos: {csv_path}")
    
    # Si se solicita dry-run, solo hacer el preprocesado y salir (no cargar TF/modelo)
    if args.dry_run:
        print("\nüß™ MODO dry-run: solo preprocesado (resample a 1 minuto)")
        try:
            # Cargar CSV y aplicar resample similar al script de comprobaci√≥n
            df = pd.read_csv(csv_path)
            print(f"   Total de registros (raw): {len(df):,}")

            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                cols = ['timestamp', 'temperatura', 'humedad', 'presion']
                missing = [c for c in cols if c not in df.columns]
                if missing:
                    print(f"Faltan columnas necesarias para resample: {missing}")
                    return

                df_num = df[cols].copy()
                for c in ['temperatura', 'humedad', 'presion']:
                    df_num[c] = pd.to_numeric(df_num[c], errors='coerce')

                df_res = df_num.set_index('timestamp').resample('1min').mean().dropna().reset_index()
                outp = base_dir / 'sensor_data_resampled.csv'
                df_res.to_csv(outp, index=False)
                print(f"   ‚úÖ Resample completado. Filas resultantes: {len(df_res):,}")
                print(f"   Muestra guardada en: {outp}")
            else:
                print("   ‚ö†Ô∏è No hay columna 'timestamp' en el CSV; nada que resamplear")
            return
        except Exception as e:
            print(f"   ‚ùå Error en dry-run: {e}")
            return

    # 2. Cargar modelo
    try:
        import tensorflow as tf
        from tensorflow import keras
        model = keras.models.load_model(model_path, compile=False)
        print(f"\n‚úÖ Modelo cargado correctamente")
        print(f"   Entrada: {model.input_shape}")
    except Exception as e:
        print(f"‚ùå Error cargando modelo: {e}")
        sys.exit(1)
    
    # 3. Cargar scaler
    try:
        import joblib
        scaler = joblib.load(scaler_path)
        print(f"‚úÖ Scaler cargado")
    except Exception as e:
        print(f"‚ùå Error cargando scaler: {e}")
        sys.exit(1)
    
    # 4. Cargar CSV
    print(f"\nüìä Cargando datos...")
    df = pd.read_csv(csv_path)
    print(f"   Total de registros (raw): {len(df):,}")

    # Intentar parsear timestamp y resamplear a 1 minuto (promediando cada ~60s)
    # Notas: los datos originales tienen un registro por segundo, pero hay 12 datos por segundo
    # seg√∫n la descripci√≥n; para obtener 1 dato por minuto se toma la media de los 60*12=720 registros
    # por minuto si corresponde. Aqu√≠ manejamos casos donde la densidad no sea exacta usando resample.
    if 'timestamp' in df.columns:
        try:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.set_index('timestamp')

            # Si hay m√∫ltiples columnas no-num√©ricas, se intentar√° convertir s√≥lo las features necesarias
            # Resample a 1 minuto y tomar la media. Esto producir√° 1 fila por minuto.
            df_min = df.resample('1T').mean()

            # Eliminar filas NaN que puedan aparecer por huecos
            df_min = df_min.dropna()

            print(f"   Registros despu√©s de resample a 1 minuto: {len(df_min):,}")
            df = df_min.reset_index()
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error al parsear/resamplear timestamps: {e}")
            print("   Usando los datos raw sin resampleo")
    else:
        print("   ‚ö†Ô∏è No hay columna 'timestamp' en el CSV; usando datos sin resampleo")
    
    # Mapeo de columnas: sensor_data.csv ‚Üí modelo (ts, hr, p0)
    feature_mapping = {
        'temperatura': 'ts',  # Temperatura del aire seco
        'humedad': 'hr',      # Humedad relativa
        'presion': 'p0'       # Presi√≥n del sensor
    }
    
    # Verificar columnas
    missing = [col for col in feature_mapping.keys() if col not in df.columns]
    if missing:
        print(f"‚ùå Columnas faltantes: {missing}")
        sys.exit(1)
    
    # Extraer features y mapear nombres
    X_raw = df[list(feature_mapping.keys())].astype(float).to_numpy()
    print(f"   Features: {list(feature_mapping.keys())}")
    print(f"   Mapeadas a: {list(feature_mapping.values())}")
    
    # 5. Configuraci√≥n de predicci√≥n
    n_pasos = 24  # Ventana de tiempo que usa el modelo (ahora cada paso es 1 minuto)
    horas_futuro = 6
    minutos_por_hora = 60
    n_predicciones = horas_futuro * minutos_por_hora  # 1 predicci√≥n por minuto
    
    print(f"\n‚öôÔ∏è  CONFIGURACI√ìN DE PREDICCI√ìN")
    print(f"   Ventana temporal (timesteps): {n_pasos}")
    print(f"   Horas a predecir: {horas_futuro}")
    print(f"   Predicciones totales: {n_predicciones:,} (1 por minuto)")
    
    # 6. Verificar que hay suficientes datos
    if len(X_raw) < n_pasos:
        print(f"\n‚ùå Datos insuficientes. Se necesitan al menos {n_pasos} registros (1 por minuto despu√©s del resample)")
        sys.exit(1)
    
    # 7. Escalar datos hist√≥ricos
    X_scaled = scaler.transform(X_raw)
    
    # 8. Obtener la √∫ltima ventana disponible
    ultima_ventana = X_scaled[-n_pasos:].copy()  # √öltimos 24 registros
    
    print(f"\nüîÑ Generando predicciones iterativas...")
    print(f"   (Esto deber√≠a ser r√°pido: {n_predicciones:,} predicciones por minuto)")
    
    # 9. Predicci√≥n iterativa
    predicciones_temp = []
    ventana_actual = ultima_ventana.copy()
    
    # Para progreso
    progreso_cada = n_predicciones // 10 if n_predicciones >= 10 else 1
    
    for i in range(n_predicciones):
        # Mostrar progreso
        if (i + 1) % progreso_cada == 0 or i == 0:
            progreso = ((i + 1) / n_predicciones) * 100
            print(f"   Progreso: {progreso:.1f}% ({i+1:,}/{n_predicciones:,})")
        
    # Preparar entrada para el modelo (1, n_pasos, 3)
        X_input = ventana_actual.reshape(1, n_pasos, 3)
        
        # Predecir siguiente valor (temperatura escalada)
        pred_scaled = model.predict(X_input, verbose=0)[0][0]
        
        # Para la siguiente predicci√≥n, necesitamos estimar hr y p0
        # Usamos los √∫ltimos valores conocidos como aproximaci√≥n
        ultima_hr_scaled = ventana_actual[-1, 1]
        ultima_p0_scaled = ventana_actual[-1, 2]
        
        # Crear el nuevo registro escalado [ts_pred, hr_last, p0_last]
        nuevo_registro_scaled = np.array([pred_scaled, ultima_hr_scaled, ultima_p0_scaled])
        
        # Actualizar ventana: eliminar el primero, agregar el nuevo al final
        ventana_actual = np.vstack([ventana_actual[1:], nuevo_registro_scaled])
        
        # Guardar predicci√≥n escalada
        predicciones_temp.append(pred_scaled)
    
    print(f"   ‚úÖ Predicci√≥n completada: {len(predicciones_temp):,} valores")
    
    # 10. Desescalar predicciones
    print(f"\nüìà Convirtiendo a temperatura real...")
    
    # Crear array dummy para inverse_transform
    predicciones_array = np.array(predicciones_temp).reshape(-1, 1)
    dummy = np.zeros((len(predicciones_array), 3))
    dummy[:, 0] = predicciones_array.flatten()
    
    # Usar hr y p0 del √∫ltimo registro como referencia
    dummy[:, 1] = X_scaled[-1, 1]
    dummy[:, 2] = X_scaled[-1, 2]
    
    predicciones_reales = scaler.inverse_transform(dummy)[:, 0]
    
    # 11. Crear timestamps para las predicciones
    print(f"\nüìÖ Generando timestamps...")
    
    if 'timestamp' in df.columns:
        try:
            ultimo_timestamp = pd.to_datetime(df['timestamp'].iloc[-1])
            print(f"   √öltimo timestamp en dataset: {ultimo_timestamp}")
        except:
            ultimo_timestamp = datetime.now()
            print(f"   Usando timestamp actual: {ultimo_timestamp}")
    else:
        ultimo_timestamp = datetime.now()
        print(f"   No hay columna timestamp, usando: {ultimo_timestamp}")
    
    # Generar timestamps futuros (1 por minuto)
    timestamps_futuros = [ultimo_timestamp + timedelta(minutes=i+1) for i in range(n_predicciones)]
    
    # 12. Crear DataFrame de resultados
    resultado_df = pd.DataFrame({
        'timestamp': timestamps_futuros,
        'temperatura_predicha': predicciones_reales,
        'segundos_desde_inicio': [ (i+1)*60 for i in range(n_predicciones)],
        'minutos_desde_inicio': range(1, n_predicciones + 1),
        'horas_desde_inicio': [(i + 1) / 60 for i in range(n_predicciones)]
    })
    
    # 13. Guardar resultados
    output_path = base_dir / "predicciones_6_horas.csv"
    resultado_df.to_csv(output_path, index=False)
    print(f"\nüíæ Predicciones guardadas en: {output_path.name}")
    
    # 14. Estad√≠sticas y resumen
    print(f"\n" + "=" * 70)
    print("üìä RESUMEN DE PREDICCIONES")
    print("=" * 70)
    
    ultima_temp_real = df['temperatura'].iloc[-1]
    primera_pred = predicciones_reales[0]
    ultima_pred = predicciones_reales[-1]
    temp_min = predicciones_reales.min()
    temp_max = predicciones_reales.max()
    temp_media = predicciones_reales.mean()
    temp_std = predicciones_reales.std()
    
    print(f"\nüå°Ô∏è  Temperatura actual (√∫ltima en dataset): {ultima_temp_real:.2f} ¬∞C")
    print(f"üîÆ Primera predicci√≥n (+1min):             {primera_pred:.2f} ¬∞C")
    print(f"üîÆ √öltima predicci√≥n (+6h):                {ultima_pred:.2f} ¬∞C")
    print(f"\nüìà Estad√≠sticas de las pr√≥ximas 6 horas:")
    print(f"   Temperatura m√≠nima:    {temp_min:.2f} ¬∞C")
    print(f"   Temperatura m√°xima:    {temp_max:.2f} ¬∞C")
    print(f"   Temperatura promedio:  {temp_media:.2f} ¬∞C")
    print(f"   Desviaci√≥n est√°ndar:   {temp_std:.2f} ¬∞C")
    
    # Cambio total
    cambio_total = ultima_pred - ultima_temp_real
    print(f"\nüìä Cambio predicho en 6 horas: {cambio_total:+.2f} ¬∞C")
    
    # 15. Muestras de predicciones en diferentes momentos
    print(f"\nüîç MUESTRAS DE PREDICCIONES:")
    print(f"\n{'Tiempo':<15} {'Timestamp':<20} {'Temp (¬∞C)':<10}")
    print("-" * 50)
    
    momentos = [
        (0, "Inicio (+1min)"),
        (15-1, "+15 minutos"),
        (30-1, "+30 minutos"),
        (60-1, "+1 hora"),
        (60*2-1, "+2 horas"),
        (60*3-1, "+3 horas"),
        (60*6-1, "+6 horas")
    ]
    
    for idx, label in momentos:
        if idx < len(resultado_df):
            ts = resultado_df.iloc[idx]['timestamp'].strftime('%Y-%m-%d %H:%M:%S')
            temp = resultado_df.iloc[idx]['temperatura_predicha']
            print(f"{label:<15} {ts:<20} {temp:>8.2f}")
    
    print(f"\n" + "=" * 70)
    print("‚úÖ Proceso completado exitosamente")
    print("=" * 70)
    
    print(f"\nüí° Puedes visualizar los resultados con:")
    print(f"   python visualizar_predicciones.py")

if __name__ == "__main__":
    main()

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-B1Pu_jtb4F5","executionInfo":{"status":"ok","timestamp":1760361666371,"user_tz":180,"elapsed":917951,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"feed7e8b-2a1b-4c91-e99a-605ca021959a"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Columnas detectadas: Index(['momento', 'ts', 'td', 'tMin12Horas', 'tMax12Horas', 'tMin24Horas',\n","       'hr', 'p0', 'qfe1', 'qfe2', 'qff', 'qnh', 'tPromedio24h', 'deltaTemp1h',\n","       'deltaPresion1h', 'humedadRelativaCambio'],\n","      dtype='object')\n","📊 Total de filas luego de limpiar: 96566\n","✅ Secuencias creadas: X=(96542, 24, 15), y=(96542,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - loss: 0.0238 - mae: 0.0956 - val_loss: 0.0025 - val_mae: 0.0431\n","Epoch 2/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0594 - val_loss: 0.0012 - val_mae: 0.0272\n","Epoch 3/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0575 - val_loss: 5.9358e-04 - val_mae: 0.0195\n","Epoch 4/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0560 - val_loss: 0.0017 - val_mae: 0.0325\n","Epoch 5/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0548 - val_loss: 9.9663e-04 - val_mae: 0.0248\n","Epoch 6/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0540 - val_loss: 5.3553e-04 - val_mae: 0.0182\n","Epoch 7/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0531 - val_loss: 0.0012 - val_mae: 0.0295\n","Epoch 8/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0534 - val_loss: 8.5169e-04 - val_mae: 0.0223\n","Epoch 9/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0535 - val_loss: 0.0011 - val_mae: 0.0278\n","Epoch 10/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0054 - mae: 0.0530 - val_loss: 8.8176e-04 - val_mae: 0.0235\n","Epoch 11/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0519 - val_loss: 6.2863e-04 - val_mae: 0.0204\n","Epoch 12/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0518 - val_loss: 7.7966e-04 - val_mae: 0.0215\n","Epoch 13/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0515 - val_loss: 4.0948e-04 - val_mae: 0.0157\n","Epoch 14/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0520 - val_loss: 5.0372e-04 - val_mae: 0.0178\n","Epoch 15/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0517 - val_loss: 0.0013 - val_mae: 0.0271\n","Epoch 16/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 4.8706e-04 - val_mae: 0.0175\n","Epoch 17/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0510 - val_loss: 9.7049e-04 - val_mae: 0.0263\n","Epoch 18/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0505 - val_loss: 5.3425e-04 - val_mae: 0.0176\n","Epoch 19/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 4.0031e-04 - val_mae: 0.0157\n","Epoch 20/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 6.4248e-04 - val_mae: 0.0203\n","Epoch 21/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0504 - val_loss: 0.0024 - val_mae: 0.0369\n","Epoch 22/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 7.9020e-04 - val_mae: 0.0226\n","Epoch 23/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 0.0013 - val_mae: 0.0290\n","Epoch 24/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 4.6686e-04 - val_mae: 0.0166\n","Epoch 25/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 8.1078e-04 - val_mae: 0.0228\n","Epoch 26/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0497 - val_loss: 6.7848e-04 - val_mae: 0.0197\n","Epoch 27/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 5.3024e-04 - val_mae: 0.0176\n","Epoch 28/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.3657e-04 - val_mae: 0.0163\n","Epoch 29/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 3.7822e-04 - val_mae: 0.0152\n","Epoch 30/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 4.2350e-04 - val_mae: 0.0161\n","Epoch 31/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 6.0196e-04 - val_mae: 0.0190\n","Epoch 32/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0496 - val_loss: 8.4076e-04 - val_mae: 0.0228\n","Epoch 33/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 4.8079e-04 - val_mae: 0.0166\n","Epoch 34/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.7217e-04 - val_mae: 0.0172\n","Epoch 35/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.0184e-04 - val_mae: 0.0159\n","Epoch 36/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0487 - val_loss: 5.5092e-04 - val_mae: 0.0179\n","Epoch 37/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 3.3302e-04 - val_mae: 0.0139\n","Epoch 38/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 9.8238e-04 - val_mae: 0.0260\n","Epoch 39/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.1797e-04 - val_mae: 0.0166\n","Epoch 40/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0486 - val_loss: 6.4807e-04 - val_mae: 0.0205\n","Epoch 41/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0487 - val_loss: 4.2618e-04 - val_mae: 0.0160\n","Epoch 42/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0492 - val_loss: 5.1827e-04 - val_mae: 0.0182\n","Epoch 43/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0489 - val_loss: 5.2594e-04 - val_mae: 0.0187\n","Epoch 44/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 4.8642e-04 - val_mae: 0.0178\n","Epoch 45/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0492 - val_loss: 4.6694e-04 - val_mae: 0.0171\n","Epoch 46/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 3.4702e-04 - val_mae: 0.0147\n","Epoch 47/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 3.9207e-04 - val_mae: 0.0155\n","\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3.6404e-04 - mae: 0.0146\n","📉 MAE en test: 0.01 °C\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["🌡️ Temperatura predicha a futuro: 14.09 °C\n","✅ Modelo guardado como 'modelo_lstm_clima.h5'\n","✅ Scaler guardado como 'scaler_clima.pkl'\n"]}],"source":["# =========================================\n","# Predicción de temperatura futura con LSTM\n","# =========================================\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","import joblib\n","\n","# 1. Cargar datos correctamente\n","df = pd.read_csv(\"dataset_ml.csv\", sep=\";\", decimal=\".\", encoding=\"utf-8\")\n","\n","# Quitar espacios extra en nombres de columnas\n","df.columns = df.columns.str.strip()\n","\n","print(\"✅ Columnas detectadas:\", df.columns)\n","\n","# 2. Procesar columna de tiempo si existe\n","if 'momento' in df.columns:\n","    df['momento'] = pd.to_datetime(df['momento'], errors='coerce')\n","    cols = df.columns.drop('momento')\n","else:\n","    cols = df.columns\n","\n","# 3. Convertir a numérico y limpiar valores inválidos\n","df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n","df = df.replace([np.inf, -np.inf], np.nan).dropna()\n","\n","# Verificar cantidad de filas\n","print(f\"📊 Total de filas luego de limpiar: {len(df)}\")\n","\n","# 4. Escalado de todas las variables de entrada\n","scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(df[cols])\n","\n","# Guardar scaler para uso futuro\n","joblib.dump(scaler, \"scaler_clima.pkl\")\n","\n","# 5. Crear secuencias de tiempo\n","def crear_secuencias(datos, n_pasos, columna_objetivo):\n","    X, y = [], []\n","    for i in range(n_pasos, len(datos)):\n","        X.append(datos[i - n_pasos:i])\n","        y.append(datos[i, columna_objetivo])\n","    return np.array(X), np.array(y)\n","\n","# Usaremos 24 pasos (por ejemplo, 24 horas si los datos son horarios)\n","n_pasos = 24\n","# Buscar el índice de la columna 'ts' (temperatura) en el escalado\n","columna_objetivo = list(cols).index('ts')\n","\n","X, y = crear_secuencias(scaled_data, n_pasos, columna_objetivo)\n","\n","print(f\"✅ Secuencias creadas: X={X.shape}, y={y.shape}\")\n","\n","# 6. Dividir en entrenamiento y test\n","porc_entrenamiento = 0.8\n","n_train = int(len(X) * porc_entrenamiento)\n","\n","X_train, X_test = X[:n_train], X[n_train:]\n","y_train, y_test = y[:n_train], y[n_train:]\n","\n","# 7. Construcción del modelo LSTM\n","model = Sequential()\n","model.add(LSTM(128, return_sequences=True, input_shape=(n_pasos, X.shape[2])))\n","model.add(Dropout(0.2))\n","model.add(LSTM(64))\n","model.add(Dropout(0.2))\n","model.add(Dense(1))  # salida: temperatura futura\n","\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","# 8. Entrenamiento\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# 9. Evaluación del modelo\n","loss, mae = model.evaluate(X_test, y_test)\n","print(f\"📉 MAE en test: {mae:.2f} °C\")\n","\n","# 10. Predicción futura usando la última ventana\n","ultima_secuencia = X[-1].reshape(1, n_pasos, X.shape[2])\n","prediccion_escalada = model.predict(ultima_secuencia)[0][0]\n","\n","# 11. Invertir el escalado para obtener la temperatura real\n","dummy = np.zeros((1, scaled_data.shape[1]))\n","dummy[0, columna_objetivo] = prediccion_escalada\n","prediccion_real = scaler.inverse_transform(dummy)[0, columna_objetivo]\n","\n","print(f\"🌡️ Temperatura predicha a futuro: {prediccion_real:.2f} °C\")\n","\n","# 12. Guardar modelo y scaler\n","model.save(\"modelo_lstm_clima.h5\")\n","print(\"✅ Modelo guardado como 'modelo_lstm_clima.h5'\")\n","print(\"✅ Scaler guardado como 'scaler_clima.pkl'\")"]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAwL7bM4gOjb","executionInfo":{"status":"ok","timestamp":1760358061091,"user_tz":180,"elapsed":45577,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"ad711f79-b3ae-4837-8062-de6604df634d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow\n","  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Collecting astunparse>=1.6.0 (from tensorflow)\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n","Collecting flatbuffers>=24.3.25 (from tensorflow)\n","  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n","Collecting google_pasta>=0.1.1 (from tensorflow)\n","  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n","Collecting libclang>=13.0.0 (from tensorflow)\n","  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.32.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n","Collecting tensorboard~=2.20.0 (from tensorflow)\n","  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n","Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n","  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n","  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n","Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n","  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n","Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m716.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n","Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m135.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorboard-data-server, google_pasta, tensorboard, astunparse, tensorflow\n","Successfully installed astunparse-1.6.3 flatbuffers-25.9.23 google_pasta-0.2.0 libclang-18.1.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 werkzeug-3.1.3 wheel-0.45.1\n"]}]},{"cell_type":"code","source":["# =========================================\n","# Predicción de temperatura futura con GRU\n","# =========================================\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","model_gru = Sequential()\n","model_gru.add(GRU(128, return_sequences=True, input_shape=(n_pasos, X.shape[2])))\n","model_gru.add(Dropout(0.2))\n","model_gru.add(GRU(64))\n","model_gru.add(Dropout(0.2))\n","model_gru.add(Dense(1))\n","\n","model_gru.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history_gru = model_gru.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","loss_gru, mae_gru = model_gru.evaluate(X_test, y_test)\n","print(f\"📉 MAE GRU: {mae_gru:.2f} °C\")\n","\n","model_gru.save(\"modelo_gru_clima.h5\")\n","print(\"✅ Modelo GRU guardado como 'modelo_gru_clima.h5'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHJGWN4Yzqjn","executionInfo":{"status":"ok","timestamp":1760363627476,"user_tz":180,"elapsed":670962,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"bddb4e78-749e-4e65-c09d-8941464eb0c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0242 - mae: 0.1005 - val_loss: 0.0028 - val_mae: 0.0449\n","Epoch 2/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0066 - mae: 0.0595 - val_loss: 0.0010 - val_mae: 0.0247\n","Epoch 3/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0557 - val_loss: 9.8220e-04 - val_mae: 0.0251\n","Epoch 4/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0548 - val_loss: 9.9329e-04 - val_mae: 0.0256\n","Epoch 5/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0054 - mae: 0.0533 - val_loss: 9.4119e-04 - val_mae: 0.0241\n","Epoch 6/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0052 - mae: 0.0525 - val_loss: 6.2185e-04 - val_mae: 0.0201\n","Epoch 7/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0052 - mae: 0.0521 - val_loss: 9.3193e-04 - val_mae: 0.0241\n","Epoch 8/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0053 - mae: 0.0527 - val_loss: 5.6385e-04 - val_mae: 0.0184\n","Epoch 9/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0515 - val_loss: 6.7713e-04 - val_mae: 0.0209\n","Epoch 10/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0051 - mae: 0.0518 - val_loss: 7.6166e-04 - val_mae: 0.0214\n","Epoch 11/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0517 - val_loss: 0.0014 - val_mae: 0.0287\n","Epoch 12/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0051 - mae: 0.0517 - val_loss: 5.1327e-04 - val_mae: 0.0172\n","Epoch 13/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0515 - val_loss: 0.0011 - val_mae: 0.0280\n","Epoch 14/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0510 - val_loss: 4.6160e-04 - val_mae: 0.0167\n","Epoch 15/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0510 - val_loss: 7.2458e-04 - val_mae: 0.0214\n","Epoch 16/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0512 - val_loss: 4.7069e-04 - val_mae: 0.0174\n","Epoch 17/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 7.6032e-04 - val_mae: 0.0217\n","Epoch 18/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0508 - val_loss: 8.0615e-04 - val_mae: 0.0223\n","Epoch 19/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0508 - val_loss: 0.0012 - val_mae: 0.0281\n","Epoch 20/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 4.4430e-04 - val_mae: 0.0168\n","Epoch 21/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 5.6714e-04 - val_mae: 0.0186\n","Epoch 22/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0506 - val_loss: 4.5732e-04 - val_mae: 0.0170\n","Epoch 23/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 4.8388e-04 - val_mae: 0.0177\n","Epoch 24/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0504 - val_loss: 5.2879e-04 - val_mae: 0.0181\n","Epoch 25/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 4.3041e-04 - val_mae: 0.0163\n","Epoch 26/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 5.0258e-04 - val_mae: 0.0178\n","Epoch 27/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0496 - val_loss: 3.4072e-04 - val_mae: 0.0145\n","Epoch 28/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0501 - val_loss: 4.0771e-04 - val_mae: 0.0157\n","Epoch 29/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0505 - val_loss: 6.4684e-04 - val_mae: 0.0207\n","Epoch 30/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0495 - val_loss: 3.6565e-04 - val_mae: 0.0149\n","Epoch 31/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0500 - val_loss: 4.4089e-04 - val_mae: 0.0165\n","Epoch 32/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 3.6654e-04 - val_mae: 0.0150\n","Epoch 33/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 0.0010 - val_mae: 0.0255\n","Epoch 34/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0501 - val_loss: 0.0011 - val_mae: 0.0275\n","Epoch 35/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 9.3592e-04 - val_mae: 0.0256\n","Epoch 36/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 4.7378e-04 - val_mae: 0.0177\n","Epoch 37/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0496 - val_loss: 5.3415e-04 - val_mae: 0.0187\n","\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3.4524e-04 - mae: 0.0146\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["📉 MAE GRU: 0.01 °C\n","✅ Modelo GRU guardado como 'modelo_gru_clima.h5'\n"]}]},{"cell_type":"code","source":["# =========================================\n","# Modelo híbrido CNN + LSTM\n","# =========================================\n","\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n","\n","model_cnn_lstm = Sequential()\n","model_cnn_lstm.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_pasos, X.shape[2])))\n","model_cnn_lstm.add(MaxPooling1D(pool_size=2))\n","model_cnn_lstm.add(LSTM(64))\n","model_cnn_lstm.add(Dropout(0.3))\n","model_cnn_lstm.add(Dense(1))\n","\n","model_cnn_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history_cnnlstm = model_cnn_lstm.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","loss_cnnlstm, mae_cnnlstm = model_cnn_lstm.evaluate(X_test, y_test)\n","print(f\"📉 MAE CNN+LSTM: {mae_cnnlstm:.2f} °C\")\n","\n","model_cnn_lstm.save(\"modelo_cnn_lstm_clima.h5\")\n","print(\"✅ Modelo CNN+LSTM guardado como 'modelo_cnn_lstm_clima.h5'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APCwB7BOz_MX","executionInfo":{"status":"ok","timestamp":1760364114823,"user_tz":180,"elapsed":469605,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"e529f261-d4cf-456c-89af-80fa922427e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.0360 - mae: 0.1170 - val_loss: 0.0017 - val_mae: 0.0326\n","Epoch 2/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0711 - val_loss: 0.0027 - val_mae: 0.0414\n","Epoch 3/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0693 - val_loss: 0.0013 - val_mae: 0.0278\n","Epoch 4/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0677 - val_loss: 0.0012 - val_mae: 0.0266\n","Epoch 5/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0083 - mae: 0.0658 - val_loss: 0.0019 - val_mae: 0.0329\n","Epoch 6/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0083 - mae: 0.0657 - val_loss: 0.0014 - val_mae: 0.0314\n","Epoch 7/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0083 - mae: 0.0651 - val_loss: 8.9853e-04 - val_mae: 0.0229\n","Epoch 8/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0080 - mae: 0.0642 - val_loss: 7.8389e-04 - val_mae: 0.0215\n","Epoch 9/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0080 - mae: 0.0635 - val_loss: 0.0014 - val_mae: 0.0291\n","Epoch 10/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0080 - mae: 0.0637 - val_loss: 9.1042e-04 - val_mae: 0.0231\n","Epoch 11/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0080 - mae: 0.0639 - val_loss: 0.0019 - val_mae: 0.0355\n","Epoch 12/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0632 - val_loss: 6.5339e-04 - val_mae: 0.0200\n","Epoch 13/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0633 - val_loss: 8.9072e-04 - val_mae: 0.0240\n","Epoch 14/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0079 - mae: 0.0634 - val_loss: 0.0017 - val_mae: 0.0351\n","Epoch 15/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0630 - val_loss: 7.7469e-04 - val_mae: 0.0224\n","Epoch 16/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0629 - val_loss: 6.2864e-04 - val_mae: 0.0199\n","Epoch 17/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0626 - val_loss: 6.8077e-04 - val_mae: 0.0201\n","Epoch 18/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0630 - val_loss: 6.5330e-04 - val_mae: 0.0200\n","Epoch 19/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0627 - val_loss: 5.7951e-04 - val_mae: 0.0188\n","Epoch 20/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0623 - val_loss: 9.4914e-04 - val_mae: 0.0249\n","Epoch 21/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0629 - val_loss: 5.2909e-04 - val_mae: 0.0180\n","Epoch 22/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0075 - mae: 0.0618 - val_loss: 7.8096e-04 - val_mae: 0.0216\n","Epoch 23/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0622 - val_loss: 7.5798e-04 - val_mae: 0.0228\n","Epoch 24/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0618 - val_loss: 7.7391e-04 - val_mae: 0.0226\n","Epoch 25/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0077 - mae: 0.0625 - val_loss: 0.0023 - val_mae: 0.0404\n","Epoch 26/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0621 - val_loss: 8.1744e-04 - val_mae: 0.0227\n","Epoch 27/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0621 - val_loss: 0.0011 - val_mae: 0.0256\n","Epoch 28/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0622 - val_loss: 0.0018 - val_mae: 0.0359\n","Epoch 29/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0622 - val_loss: 5.5535e-04 - val_mae: 0.0185\n","Epoch 30/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0623 - val_loss: 0.0010 - val_mae: 0.0262\n","Epoch 31/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0619 - val_loss: 0.0013 - val_mae: 0.0288\n","\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.6212e-04 - mae: 0.0185\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["📉 MAE CNN+LSTM: 0.02 °C\n","✅ Modelo CNN+LSTM guardado como 'modelo_cnn_lstm_clima.h5'\n"]}]},{"cell_type":"code","source":["# =========================================\n","# Modelo basado en Transformer simple\n","# =========================================\n","\n","from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Flatten\n","import tensorflow as tf\n","inputs = tf.keras.Input(shape=(n_pasos, X.shape[2]))\n","x = MultiHeadAttention(num_heads=4, key_dim=16)(inputs, inputs)\n","x = LayerNormalization(epsilon=1e-6)(x)\n","x = Flatten()(x)\n","x = Dense(64, activation='relu')(x)\n","x = Dropout(0.3)(x)\n","outputs = Dense(1)(x)\n","\n","model_transformer = tf.keras.Model(inputs, outputs)\n","model_transformer.compile(optimizer=Adam(0.001), loss='mse', metrics=['mae'])\n","\n","history_trans = model_transformer.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","loss_trans, mae_trans = model_transformer.evaluate(X_test, y_test)\n","print(f\"📉 MAE Transformer: {mae_trans:.2f} °C\")\n","\n","model_transformer.save(\"modelo_transformer_clima.h5\")\n","print(\"✅ Modelo Transformer guardado como 'modelo_transformer_clima.h5'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBVh8f6h0AT2","executionInfo":{"status":"ok","timestamp":1760366561747,"user_tz":180,"elapsed":239753,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"234c14fc-c0d3-43ce-d897-96bc1032a7db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1362 - mae: 0.2151 - val_loss: 0.0280 - val_mae: 0.1340\n","Epoch 2/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0300 - mae: 0.1266 - val_loss: 0.0097 - val_mae: 0.0763\n","Epoch 3/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0273 - mae: 0.1207 - val_loss: 0.0057 - val_mae: 0.0601\n","Epoch 4/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0262 - mae: 0.1183 - val_loss: 0.0035 - val_mae: 0.0486\n","Epoch 5/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0255 - mae: 0.1160 - val_loss: 0.0038 - val_mae: 0.0494\n","Epoch 6/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0248 - mae: 0.1139 - val_loss: 0.0076 - val_mae: 0.0694\n","Epoch 7/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0245 - mae: 0.1131 - val_loss: 0.0067 - val_mae: 0.0655\n","Epoch 8/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0239 - mae: 0.1108 - val_loss: 0.0049 - val_mae: 0.0591\n","Epoch 9/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0233 - mae: 0.1100 - val_loss: 0.0102 - val_mae: 0.0826\n","Epoch 10/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0236 - mae: 0.1098 - val_loss: 0.0046 - val_mae: 0.0560\n","Epoch 11/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0231 - mae: 0.1090 - val_loss: 0.0021 - val_mae: 0.0359\n","Epoch 12/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0224 - mae: 0.1068 - val_loss: 0.0039 - val_mae: 0.0515\n","Epoch 13/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0214 - mae: 0.1042 - val_loss: 0.0014 - val_mae: 0.0290\n","Epoch 14/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0212 - mae: 0.1033 - val_loss: 0.0014 - val_mae: 0.0298\n","Epoch 15/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0188 - mae: 0.0979 - val_loss: 0.0018 - val_mae: 0.0337\n","Epoch 16/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0176 - mae: 0.0948 - val_loss: 0.0051 - val_mae: 0.0571\n","Epoch 17/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.0912 - val_loss: 0.0031 - val_mae: 0.0476\n","Epoch 18/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0162 - mae: 0.0906 - val_loss: 0.0051 - val_mae: 0.0576\n","Epoch 19/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0164 - mae: 0.0909 - val_loss: 0.0033 - val_mae: 0.0476\n","Epoch 20/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0164 - mae: 0.0908 - val_loss: 9.9910e-04 - val_mae: 0.0244\n","Epoch 21/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.0913 - val_loss: 0.0018 - val_mae: 0.0344\n","Epoch 22/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0166 - mae: 0.0915 - val_loss: 0.0021 - val_mae: 0.0378\n","Epoch 23/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0162 - mae: 0.0897 - val_loss: 0.0012 - val_mae: 0.0270\n","Epoch 24/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0155 - mae: 0.0884 - val_loss: 0.0053 - val_mae: 0.0632\n","Epoch 25/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0896 - val_loss: 0.0020 - val_mae: 0.0347\n","Epoch 26/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0156 - mae: 0.0886 - val_loss: 0.0035 - val_mae: 0.0487\n","Epoch 27/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0896 - val_loss: 0.0013 - val_mae: 0.0287\n","Epoch 28/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0897 - val_loss: 0.0070 - val_mae: 0.0782\n","Epoch 29/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0154 - mae: 0.0882 - val_loss: 0.0011 - val_mae: 0.0254\n","Epoch 30/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0158 - mae: 0.0889 - val_loss: 0.0029 - val_mae: 0.0405\n","\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0251\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["📉 MAE Transformer: 0.02 °C\n","✅ Modelo Transformer guardado como 'modelo_transformer_clima.h5'\n"]}]},{"cell_type":"code","source":["#codigo actualizado del primero\n","# =========================================\n","# Predicción de temperatura futura con LSTM (usando todas las columnas)\n","# =========================================\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","import joblib\n","import math\n","\n","# 1. Cargar datos\n","df = pd.read_csv(\"dataset_ml.csv\", sep=\";\", decimal=\".\", encoding=\"utf-8\", low_memory=False)\n","\n","# Limpiar nombres de columnas\n","df.columns = df.columns.str.strip()\n","\n","# 2. Procesar columna de tiempo\n","if 'momento' in df.columns:\n","    df['momento'] = pd.to_datetime(df['momento'], errors='coerce')\n","    df = df.dropna(subset=['momento'])\n","    df = df.sort_values('momento')\n","    cols = df.columns.drop('momento')\n","else:\n","    cols = df.columns\n","\n","# 3. Limpieza de datos\n","# Convertir todas las columnas numéricas correctamente\n","df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n","\n","# Reemplazar valores absurdos (muy grandes o pequeños)\n","df = df.replace([np.inf, -np.inf], np.nan)\n","df[cols] = df[cols].apply(lambda x: np.where(np.abs(x) > 1e6, np.nan, x))  # filtra extremos\n","df = df.dropna()\n","\n","print(f\"✅ Datos limpios: {len(df)} filas\")\n","print(\"✅ Columnas utilizadas:\", list(cols))\n","\n","# 4. Escalado\n","scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(df[cols])\n","joblib.dump(scaler, \"scaler_clima.pkl\")\n","\n","# 5. Crear secuencias\n","def crear_secuencias(datos, n_pasos, columna_objetivo):\n","    X, y = [], []\n","    for i in range(n_pasos, len(datos)):\n","        X.append(datos[i - n_pasos:i])\n","        y.append(datos[i, columna_objetivo])\n","    return np.array(X), np.array(y)\n","\n","n_pasos = 24\n","columna_objetivo = list(cols).index('ts')  # Temperatura superficial\n","\n","X, y = crear_secuencias(scaled_data, n_pasos, columna_objetivo)\n","print(f\"📈 Secuencias creadas: X={X.shape}, y={y.shape}\")\n","\n","# 6. División train/test\n","n_train = int(len(X) * 0.8)\n","X_train, X_test = X[:n_train], X[n_train:]\n","y_train, y_test = y[:n_train], y[n_train:]\n","\n","# 7. Modelo LSTM\n","model = Sequential([\n","    LSTM(128, return_sequences=True, input_shape=(n_pasos, X.shape[2])),\n","    Dropout(0.2),\n","    LSTM(64),\n","    Dropout(0.2),\n","    Dense(1)\n","])\n","\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","# 8. Entrenamiento\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# 9. Evaluación\n","y_pred = model.predict(X_test)\n","mae = mean_absolute_error(y_test, y_pred)\n","rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n","r2 = r2_score(y_test, y_pred)\n","\n","print(\"\\n📊 MÉTRICAS DEL MODELO:\")\n","print(f\"MAE  = {mae:.4f}\")\n","print(f\"RMSE = {rmse:.4f}\")\n","print(f\"R²   = {r2:.4f}\")\n","\n","# 10. Predicción 1–6 horas futuras\n","ultima_secuencia = X[-1].copy()\n","predicciones_futuras = []\n","\n","for h in range(6):\n","    prediccion_escalada = model.predict(ultima_secuencia.reshape(1, n_pasos, X.shape[2]))[0][0]\n","    predicciones_futuras.append(prediccion_escalada)\n","\n","    # Actualizar ventana\n","    nueva_fila = ultima_secuencia[-1].copy()\n","    nueva_fila[columna_objetivo] = prediccion_escalada\n","    ultima_secuencia = np.vstack([ultima_secuencia[1:], nueva_fila])\n","\n","# 11. Invertir el escalado\n","dummy = np.zeros((len(predicciones_futuras), scaled_data.shape[1]))\n","dummy[:, columna_objetivo] = predicciones_futuras\n","predicciones_reales = scaler.inverse_transform(dummy)[:, columna_objetivo]\n","\n","print(\"\\n🌡️ PREDICCIONES FUTURAS (próximas 6 horas):\")\n","for i, temp in enumerate(predicciones_reales, start=1):\n","    print(f\"➡️ +{i}h: {temp:.2f} °C\")\n","\n","# 12. Guardar modelo y scaler\n","model.save(\"modelo_lstm_clima.h5\")\n","print(\"\\n✅ Modelo guardado como 'modelo_lstm_clima.h5'\")\n","print(\"✅ Scaler guardado como 'scaler_clima.pkl'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DI_UsdCnbix","outputId":"6bd1a355-87bc-4c6c-919e-daf6eb7d57b0","executionInfo":{"status":"ok","timestamp":1760477813200,"user_tz":180,"elapsed":313199,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Datos limpios: 82734 filas\n","✅ Columnas utilizadas: ['ts', 'td', 'tMin12Horas', 'tMax12Horas', 'tMin24Horas', 'hr', 'p0', 'qfe1', 'qfe2', 'qff', 'qnh', 'tPromedio24h', 'deltaTemp1h', 'deltaPresion1h', 'humedadRelativaCambio']\n","📈 Secuencias creadas: X=(82710, 24, 15), y=(82710,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0300 - mae: 0.1028 - val_loss: 0.0025 - val_mae: 0.0421\n","Epoch 2/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0073 - mae: 0.0632 - val_loss: 7.0438e-04 - val_mae: 0.0213\n","Epoch 3/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0064 - mae: 0.0586 - val_loss: 0.0037 - val_mae: 0.0492\n","Epoch 4/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0064 - mae: 0.0583 - val_loss: 7.5404e-04 - val_mae: 0.0228\n","Epoch 5/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0573 - val_loss: 6.9317e-04 - val_mae: 0.0202\n","Epoch 6/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0566 - val_loss: 8.8577e-04 - val_mae: 0.0231\n","Epoch 7/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0554 - val_loss: 7.6431e-04 - val_mae: 0.0212\n","Epoch 8/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0057 - mae: 0.0548 - val_loss: 0.0013 - val_mae: 0.0260\n","Epoch 9/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0057 - mae: 0.0545 - val_loss: 4.9682e-04 - val_mae: 0.0171\n","Epoch 10/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0055 - mae: 0.0538 - val_loss: 9.2462e-04 - val_mae: 0.0220\n","Epoch 11/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0055 - mae: 0.0537 - val_loss: 4.2374e-04 - val_mae: 0.0162\n","Epoch 12/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0056 - mae: 0.0540 - val_loss: 5.6572e-04 - val_mae: 0.0179\n","Epoch 13/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 0.0055 - mae: 0.0537 - val_loss: 6.8057e-04 - val_mae: 0.0185\n","Epoch 14/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0053 - mae: 0.0526 - val_loss: 8.6547e-04 - val_mae: 0.0219\n","Epoch 15/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0054 - mae: 0.0531 - val_loss: 6.3460e-04 - val_mae: 0.0199\n","Epoch 16/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0052 - mae: 0.0526 - val_loss: 6.6130e-04 - val_mae: 0.0199\n","Epoch 17/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0052 - mae: 0.0520 - val_loss: 6.1063e-04 - val_mae: 0.0187\n","Epoch 18/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0052 - mae: 0.0520 - val_loss: 4.8124e-04 - val_mae: 0.0167\n","Epoch 19/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0053 - mae: 0.0523 - val_loss: 0.0012 - val_mae: 0.0266\n","Epoch 20/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0053 - mae: 0.0523 - val_loss: 9.9733e-04 - val_mae: 0.0238\n","Epoch 21/100\n","\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.0051 - mae: 0.0514 - val_loss: 6.8173e-04 - val_mae: 0.0196\n","\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n","\n","📊 MÉTRICAS DEL MODELO:\n","MAE  = 0.0162\n","RMSE = 0.0206\n","R²   = 0.9995\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\n","🌡️ PREDICCIONES FUTURAS (próximas 6 horas):\n","➡️ +1h: 16.25 °C\n","➡️ +2h: 16.37 °C\n","➡️ +3h: 16.44 °C\n","➡️ +4h: 16.47 °C\n","➡️ +5h: 16.50 °C\n","➡️ +6h: 16.53 °C\n","\n","✅ Modelo guardado como 'modelo_lstm_clima.h5'\n","✅ Scaler guardado como 'scaler_clima.pkl'\n"]}]},{"cell_type":"code","source":["#codigo actualizado del segundo\n","# =========================================\n","# Predicción de temperatura futura con GRU\n","# =========================================\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","import joblib\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# ===============================\n","# 1️⃣ Cargar y limpiar datos\n","# ===============================\n","df = pd.read_csv(\"dataset_ml.csv\", sep=\";\", decimal=\".\", encoding=\"utf-8\", low_memory=False)\n","df.columns = df.columns.str.strip()\n","\n","# Procesar la columna de tiempo\n","if 'momento' in df.columns:\n","    df['momento'] = pd.to_datetime(df['momento'], errors='coerce')\n","    df = df.dropna(subset=['momento'])\n","    df = df.sort_values('momento')\n","    cols = df.columns.drop('momento')\n","else:\n","    cols = df.columns\n","\n","# Convertir todas las columnas numéricas\n","df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n","df = df.replace([np.inf, -np.inf], np.nan)\n","\n","# Eliminar valores absurdamente grandes\n","df[cols] = df[cols].apply(lambda x: np.where(np.abs(x) > 1e6, np.nan, x))\n","df = df.dropna()\n","\n","print(f\"✅ Datos limpios: {len(df)} filas\")\n","print(\"✅ Columnas utilizadas:\", list(cols))\n","\n","# ===============================\n","# 2️⃣ Escalado de todas las columnas\n","# ===============================\n","scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(df[cols])\n","joblib.dump(scaler, \"scaler_clima.pkl\")\n","\n","# ===============================\n","# 3️⃣ Crear secuencias de tiempo\n","# ===============================\n","def crear_secuencias(datos, n_pasos, columna_objetivo):\n","    X, y = [], []\n","    for i in range(n_pasos, len(datos)):\n","        X.append(datos[i - n_pasos:i])\n","        y.append(datos[i, columna_objetivo])\n","    return np.array(X), np.array(y)\n","\n","n_pasos = 24  # 24 horas previas\n","columna_objetivo = list(cols).index('ts')  # temperatura superficial\n","\n","X, y = crear_secuencias(scaled_data, n_pasos, columna_objetivo)\n","print(f\"📈 Secuencias creadas: X={X.shape}, y={y.shape}\")\n","\n","# ===============================\n","# 4️⃣ División de entrenamiento y test\n","# ===============================\n","n_train = int(len(X) * 0.8)\n","X_train, X_test = X[:n_train], X[n_train:]\n","y_train, y_test = y[:n_train], y[n_train:]\n","\n","# ===============================\n","# 5️⃣ Construcción del modelo GRU\n","# ===============================\n","model_gru = Sequential([\n","    GRU(128, return_sequences=True, input_shape=(n_pasos, X.shape[2])),\n","    Dropout(0.2),\n","    GRU(64),\n","    Dropout(0.2),\n","    Dense(1)\n","])\n","\n","model_gru.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","# ===============================\n","# 6️⃣ Entrenamiento\n","# ===============================\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history_gru = model_gru.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# ===============================\n","# 7️⃣ Evaluación del modelo\n","# ===============================\n","y_pred = model_gru.predict(X_test)\n","mae = mean_absolute_error(y_test, y_pred)\n","rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n","r2 = r2_score(y_test, y_pred)\n","\n","print(\"\\n📊 MÉTRICAS DEL MODELO GRU:\")\n","print(f\"MAE  = {mae:.4f}\")\n","print(f\"RMSE = {rmse:.4f}\")\n","print(f\"R²   = {r2:.4f}\")\n","\n","# ===============================\n","# 8️⃣ Predicción futura (1–6 horas adelante)\n","# ===============================\n","horas_a_predecir = int(input(\"\\n⏩ ¿Cuántas horas deseas predecir (1–6)? \"))\n","horas_a_predecir = max(1, min(horas_a_predecir, 6))  # limitar entre 1 y 6\n","\n","ultima_secuencia = X[-1].copy()\n","predicciones_futuras = []\n","\n","for h in range(horas_a_predecir):\n","    prediccion_escalada = model_gru.predict(ultima_secuencia.reshape(1, n_pasos, X.shape[2]))[0][0]\n","    predicciones_futuras.append(prediccion_escalada)\n","\n","    # Actualizar la secuencia\n","    nueva_fila = ultima_secuencia[-1].copy()\n","    nueva_fila[columna_objetivo] = prediccion_escalada\n","    ultima_secuencia = np.vstack([ultima_secuencia[1:], nueva_fila])\n","\n","# Invertir el escalado\n","dummy = np.zeros((len(predicciones_futuras), scaled_data.shape[1]))\n","dummy[:, columna_objetivo] = predicciones_futuras\n","predicciones_reales = scaler.inverse_transform(dummy)[:, columna_objetivo]\n","\n","print(\"\\n🌡️ PREDICCIONES FUTURAS (temperatura ts):\")\n","for i, temp in enumerate(predicciones_reales, start=1):\n","    print(f\"➡️ +{i}h: {temp:.2f} °C\")\n","\n","# ===============================\n","# 9️⃣ Guardar modelo y scaler\n","# ===============================\n","model_gru.save(\"modelo_gru_clima.h5\")\n","print(\"\\n✅ Modelo GRU guardado como 'modelo_gru_clima.h5'\")\n","print(\"✅ Scaler guardado como 'scaler_clima.pkl'\")\n"],"metadata":{"id":"fQKkxu4znibS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760484902270,"user_tz":180,"elapsed":7005430,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"7fb44e07-89db-433e-e32f-b27f692c4754"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Datos limpios: 3010374 filas\n","✅ Columnas utilizadas: ['ts', 'td', 'tMin12Horas', 'tMax12Horas', 'tMin24Horas', 'hr', 'p0', 'qfe1', 'qfe2', 'qff', 'qnh', 'tPromedio24h', 'deltaTemp1h', 'deltaPresion1h', 'humedadRelativaCambio']\n","📈 Secuencias creadas: X=(3010350, 24, 15), y=(3010350,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 7ms/step - loss: 0.0065 - mae: 0.0551 - val_loss: 5.9505e-04 - val_mae: 0.0194\n","Epoch 2/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 6ms/step - loss: 0.0050 - mae: 0.0492 - val_loss: 8.2456e-04 - val_mae: 0.0226\n","Epoch 3/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0477 - val_loss: 0.0011 - val_mae: 0.0252\n","Epoch 4/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 7ms/step - loss: 0.0071 - mae: 0.0614 - val_loss: 0.0060 - val_mae: 0.0593\n","Epoch 5/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 7ms/step - loss: 0.0102 - mae: 0.0760 - val_loss: 0.0066 - val_mae: 0.0624\n","Epoch 6/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 7ms/step - loss: 0.0107 - mae: 0.0780 - val_loss: 0.0076 - val_mae: 0.0690\n","Epoch 7/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0788 - val_loss: 0.0091 - val_mae: 0.0736\n","Epoch 8/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 7ms/step - loss: 0.0113 - mae: 0.0802 - val_loss: 0.0101 - val_mae: 0.0738\n","Epoch 9/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 7ms/step - loss: 0.0110 - mae: 0.0791 - val_loss: 0.0171 - val_mae: 0.0988\n","Epoch 10/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 7ms/step - loss: 0.0111 - mae: 0.0798 - val_loss: 0.0128 - val_mae: 0.0814\n","Epoch 11/100\n","\u001b[1m75259/75259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 7ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0184 - val_mae: 0.0982\n","\u001b[1m18815/18815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step\n","\n","📊 MÉTRICAS DEL MODELO GRU:\n","MAE  = 0.0194\n","RMSE = 0.0244\n","R²   = 0.9994\n","\n","⏩ ¿Cuántas horas deseas predecir (1–6)? 1\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\n","🌡️ PREDICCIONES FUTURAS (temperatura ts):\n","➡️ +1h: 8.80 °C\n","\n","✅ Modelo GRU guardado como 'modelo_gru_clima.h5'\n","✅ Scaler guardado como 'scaler_clima.pkl'\n"]}]},{"cell_type":"code","source":["#mejora del tercer modelo\n","# =========================================\n","# Modelo híbrido CNN + LSTM mejorado\n","# =========================================\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","import math\n","\n","# ==============================\n","# 1️⃣ Cargar y preparar los datos\n","# ==============================\n","df = pd.read_csv(\"dataset_ml.csv\", sep=\";\")\n","\n","# Convertir columna de tiempo\n","df[\"momento\"] = pd.to_datetime(df[\"momento\"], errors=\"coerce\")\n","\n","# Eliminar filas con valores nulos o corruptos\n","df = df.dropna()\n","\n","# Usamos TODAS las columnas numéricas (excepto 'momento')\n","features = df.select_dtypes(include=[np.number]).columns\n","data = df[features].values\n","\n","# Escalamos todos los valores entre 0 y 1\n","scaler = MinMaxScaler()\n","data_scaled = scaler.fit_transform(data)\n","\n","# =====================================\n","# 2️⃣ Crear secuencias para entrenamiento\n","# =====================================\n","n_pasos = 24  # 24 horas de historial para predecir\n","horizonte = int(input(\"⏱️ Ingresa cuántas horas hacia el futuro deseas predecir (1-6): \"))\n","horizonte = max(1, min(6, horizonte))  # limitar entre 1 y 6\n","\n","X, y = [], []\n","for i in range(n_pasos, len(data_scaled) - horizonte):\n","    X.append(data_scaled[i - n_pasos:i])\n","    # variable objetivo: temperatura futura (columna 'ts')\n","    y.append(data_scaled[i + horizonte, list(features).index(\"ts\")])\n","\n","X, y = np.array(X), np.array(y)\n","\n","# ==============================\n","# 3️⃣ División de datos\n","# ==============================\n","porcentaje_entrenamiento = 0.8\n","n_entrenamiento = int(len(X) * porcentaje_entrenamiento)\n","\n","X_train, X_test = X[:n_entrenamiento], X[n_entrenamiento:]\n","y_train, y_test = y[:n_entrenamiento], y[n_entrenamiento:]\n","\n","# ==============================\n","# 4️⃣ Modelo CNN + LSTM\n","# ==============================\n","model_cnn_lstm = Sequential()\n","model_cnn_lstm.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_pasos, X.shape[2])))\n","model_cnn_lstm.add(MaxPooling1D(pool_size=2))\n","model_cnn_lstm.add(LSTM(64))\n","model_cnn_lstm.add(Dropout(0.3))\n","model_cnn_lstm.add(Dense(1))\n","\n","model_cnn_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","# ==============================\n","# 5️⃣ Entrenamiento\n","# ==============================\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","history_cnnlstm = model_cnn_lstm.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# ==============================\n","# 6️⃣ Evaluación\n","# ==============================\n","y_pred = model_cnn_lstm.predict(X_test)\n","\n","# Desescalar resultados (para obtener temperatura real)\n","idx_temp = list(features).index(\"ts\")\n","temp_min, temp_max = scaler.data_min_[idx_temp], scaler.data_max_[idx_temp]\n","y_pred_real = y_pred * (temp_max - temp_min) + temp_min\n","y_test_real = y_test * (temp_max - temp_min) + temp_min\n","\n","# Métricas\n","mae = mean_absolute_error(y_test_real, y_pred_real)\n","rmse = math.sqrt(mean_squared_error(y_test_real, y_pred_real))\n","r2 = r2_score(y_test_real, y_pred_real)\n","\n","print(\"\\n📊 Resultados del modelo CNN + LSTM:\")\n","print(f\"MAE  : {mae:.2f} °C\")\n","print(f\"RMSE : {rmse:.2f} °C\")\n","print(f\"R²   : {r2:.3f}\")\n","\n","# ==============================\n","# 7️⃣ Guardar modelo\n","# ==============================\n","model_cnn_lstm.save(\"modelo_cnn_lstm_clima.h5\")\n","print(\"✅ Modelo CNN+LSTM guardado como 'modelo_cnn_lstm_clima.h5'\")\n","\n","# ==============================\n","# 8️⃣ Predicción futura (horas siguientes)\n","# ==============================\n","ultimos_datos = data_scaled[-n_pasos:]\n","entrada = np.expand_dims(ultimos_datos, axis=0)\n","prediccion_futura = []\n","\n","for i in range(horizonte):\n","    pred = model_cnn_lstm.predict(entrada)\n","    prediccion_futura.append(pred[0, 0])\n","    # desplazamos ventana y agregamos nueva predicción\n","    nueva_fila = entrada[0, -1, :].copy()\n","    nueva_fila[idx_temp] = pred[0, 0]\n","    entrada = np.append(entrada[:, 1:, :], [[nueva_fila]], axis=1)\n","\n","# Desescalar las predicciones futuras\n","prediccion_futura_real = np.array(prediccion_futura) * (temp_max - temp_min) + temp_min\n","\n","print(f\"\\n🌤️ Predicciones de temperatura para las próximas {horizonte} horas:\")\n","for i, temp in enumerate(prediccion_futura_real, start=1):\n","    print(f\"  +{i}h → {temp:.2f} °C\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AIOHSZifsQLN","executionInfo":{"status":"ok","timestamp":1760528665655,"user_tz":180,"elapsed":1953771,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"5c0b95f0-2566-453b-b933-56c6d1ae6e07"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["⏱️ Ingresa cuántas horas hacia el futuro deseas predecir (1-6): 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5ms/step - loss: 0.0012 - mae: 0.0214 - val_loss: 5.2026e-05 - val_mae: 0.0058\n","Epoch 2/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 3.1310e-04 - mae: 0.0125 - val_loss: 4.6301e-05 - val_mae: 0.0048\n","Epoch 3/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.9916e-04 - mae: 0.0121 - val_loss: 5.5929e-05 - val_mae: 0.0057\n","Epoch 4/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.9550e-04 - mae: 0.0120 - val_loss: 2.4413e-05 - val_mae: 0.0036\n","Epoch 5/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.9218e-04 - mae: 0.0119 - val_loss: 2.9099e-05 - val_mae: 0.0039\n","Epoch 6/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5ms/step - loss: 2.8799e-04 - mae: 0.0118 - val_loss: 6.4152e-05 - val_mae: 0.0063\n","Epoch 7/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5ms/step - loss: 2.8655e-04 - mae: 0.0118 - val_loss: 6.1514e-05 - val_mae: 0.0058\n","Epoch 8/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.8103e-04 - mae: 0.0116 - val_loss: 2.4996e-05 - val_mae: 0.0036\n","Epoch 9/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.8080e-04 - mae: 0.0116 - val_loss: 2.3057e-05 - val_mae: 0.0033\n","Epoch 10/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.8285e-04 - mae: 0.0116 - val_loss: 3.3762e-05 - val_mae: 0.0040\n","Epoch 11/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.8067e-04 - mae: 0.0116 - val_loss: 2.7352e-05 - val_mae: 0.0039\n","Epoch 12/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.8235e-04 - mae: 0.0116 - val_loss: 5.9183e-05 - val_mae: 0.0059\n","Epoch 13/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.8315e-04 - mae: 0.0116 - val_loss: 2.2265e-05 - val_mae: 0.0033\n","Epoch 14/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5ms/step - loss: 2.8267e-04 - mae: 0.0116 - val_loss: 6.8507e-05 - val_mae: 0.0071\n","Epoch 15/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.7809e-04 - mae: 0.0115 - val_loss: 4.0667e-05 - val_mae: 0.0047\n","Epoch 16/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.7940e-04 - mae: 0.0115 - val_loss: 8.5874e-05 - val_mae: 0.0079\n","Epoch 17/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5ms/step - loss: 2.7889e-04 - mae: 0.0115 - val_loss: 4.9532e-05 - val_mae: 0.0052\n","Epoch 18/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5ms/step - loss: 2.7880e-04 - mae: 0.0115 - val_loss: 9.2574e-05 - val_mae: 0.0080\n","Epoch 19/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.7818e-04 - mae: 0.0115 - val_loss: 2.6566e-05 - val_mae: 0.0038\n","Epoch 20/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5ms/step - loss: 2.7718e-04 - mae: 0.0115 - val_loss: 1.2918e-04 - val_mae: 0.0098\n","Epoch 21/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5ms/step - loss: 2.7741e-04 - mae: 0.0115 - val_loss: 2.4778e-05 - val_mae: 0.0035\n","Epoch 22/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - loss: 2.7762e-04 - mae: 0.0115 - val_loss: 2.2950e-05 - val_mae: 0.0034\n","Epoch 23/100\n","\u001b[1m15617/15617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5ms/step - loss: 2.7664e-04 - mae: 0.0114 - val_loss: 3.8041e-05 - val_mae: 0.0049\n","\u001b[1m3905/3905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\n","📊 Resultados del modelo CNN + LSTM:\n","MAE  : 0.13 °C\n","RMSE : 0.19 °C\n","R²   : 0.999\n","✅ Modelo CNN+LSTM guardado como 'modelo_cnn_lstm_clima.h5'\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\n","🌤️ Predicciones de temperatura para las próximas 1 horas:\n","  +1h → 33.56 °C\n"]}]},{"cell_type":"code","source":["#mejora cuarto modelo\n","# =========================================\n","# Modelo basado en Transformer simple mejorado\n","# =========================================\n","\n","import numpy as np\n","import pandas as pd\n","import math\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import (\n","    Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Flatten\n",")\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","import tensorflow as tf\n","\n","# ==============================\n","# 1️⃣ Cargar y preparar los datos\n","# ==============================\n","df = pd.read_csv(\"dataset_ml.csv\", sep=\";\")\n","\n","# Convertir columna de tiempo\n","df[\"momento\"] = pd.to_datetime(df[\"momento\"], errors=\"coerce\")\n","\n","# Eliminar filas con valores nulos o corruptos\n","df = df.dropna()\n","\n","# Usar TODAS las columnas numéricas excepto 'momento'\n","features = df.select_dtypes(include=[np.number]).columns\n","data = df[features].values\n","\n","# Escalar todas las variables\n","scaler = MinMaxScaler()\n","data_scaled = scaler.fit_transform(data)\n","\n","# =====================================\n","# 2️⃣ Crear secuencias para entrenamiento\n","# =====================================\n","n_pasos = 24  # 24 pasos (ej: 24 horas anteriores)\n","horizonte = int(input(\"⏱️ Ingresa cuántas horas hacia el futuro deseas predecir (1-6): \"))\n","horizonte = max(1, min(6, horizonte))  # limitar entre 1 y 6\n","\n","X, y = [], []\n","for i in range(n_pasos, len(data_scaled) - horizonte):\n","    X.append(data_scaled[i - n_pasos:i])\n","    # variable objetivo: temperatura superficial futura (\"ts\")\n","    y.append(data_scaled[i + horizonte, list(features).index(\"ts\")])\n","\n","X, y = np.array(X), np.array(y)\n","\n","# ==============================\n","# 3️⃣ División de datos\n","# ==============================\n","porcentaje_entrenamiento = 0.8\n","n_entrenamiento = int(len(X) * porcentaje_entrenamiento)\n","\n","X_train, X_test = X[:n_entrenamiento], X[n_entrenamiento:]\n","y_train, y_test = y[:n_entrenamiento], y[n_entrenamiento:]\n","\n","# ==============================\n","# 4️⃣ Definir modelo Transformer\n","# ==============================\n","inputs = Input(shape=(n_pasos, X.shape[2]))\n","x = MultiHeadAttention(num_heads=4, key_dim=16)(inputs, inputs)\n","x = LayerNormalization(epsilon=1e-6)(x)\n","x = Flatten()(x)\n","x = Dense(64, activation='relu')(x)\n","x = Dropout(0.3)(x)\n","outputs = Dense(1)(x)\n","\n","model_transformer = Model(inputs, outputs)\n","model_transformer.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","# ==============================\n","# 5️⃣ Entrenamiento\n","# ==============================\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","history_trans = model_transformer.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# ==============================\n","# 6️⃣ Evaluación del modelo\n","# ==============================\n","y_pred = model_transformer.predict(X_test)\n","\n","# Desescalar temperatura (variable \"ts\")\n","idx_temp = list(features).index(\"ts\")\n","temp_min, temp_max = scaler.data_min_[idx_temp], scaler.data_max_[idx_temp]\n","y_pred_real = y_pred * (temp_max - temp_min) + temp_min\n","y_test_real = y_test * (temp_max - temp_min) + temp_min\n","\n","# Calcular métricas\n","mae = mean_absolute_error(y_test_real, y_pred_real)\n","rmse = math.sqrt(mean_squared_error(y_test_real, y_pred_real))\n","r2 = r2_score(y_test_real, y_pred_real)\n","\n","print(\"\\n📊 Resultados del modelo Transformer:\")\n","print(f\"MAE  : {mae:.2f} °C\")\n","print(f\"RMSE : {rmse:.2f} °C\")\n","print(f\"R²   : {r2:.3f}\")\n","\n","# ==============================\n","# 7️⃣ Guardar modelo\n","# ==============================\n","model_transformer.save(\"modelo_transformer_clima.h5\")\n","print(\"✅ Modelo Transformer guardado como 'modelo_transformer_clima.h5'\")\n","\n","# ==============================\n","# 8️⃣ Predicción futura (1–6 horas)\n","# ==============================\n","ultimos_datos = data_scaled[-n_pasos:]\n","entrada = np.expand_dims(ultimos_datos, axis=0)\n","prediccion_futura = []\n","\n","for i in range(horizonte):\n","    pred = model_transformer.predict(entrada)\n","    prediccion_futura.append(pred[0, 0])\n","    # Actualizar la ventana\n","    nueva_fila = entrada[0, -1, :].copy()\n","    nueva_fila[idx_temp] = pred[0, 0]\n","    entrada = np.append(entrada[:, 1:, :], [[nueva_fila]], axis=1)\n","\n","# Desescalar predicciones futuras\n","prediccion_futura_real = np.array(prediccion_futura) * (temp_max - temp_min) + temp_min\n","\n","print(f\"\\n🌤️ Predicciones de temperatura para las próximas {horizonte} horas:\")\n","for i, temp in enumerate(prediccion_futura_real, start=1):\n","    print(f\"  +{i}h → {temp:.2f} °C\")\n"],"metadata":{"id":"Zk5DAX3Mq9iN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760536502259,"user_tz":180,"elapsed":5544881,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"e8fb951a-997e-4954-bbf5-ce9bcec78cad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["⏱️ Ingresa cuántas horas hacia el futuro deseas predecir (1-6): 1\n","Epoch 1/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 3ms/step - loss: 0.0048 - mae: 0.0351 - val_loss: 0.0056 - val_mae: 0.0511\n","Epoch 2/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2ms/step - loss: 8.0168e-04 - mae: 0.0199 - val_loss: 0.0056 - val_mae: 0.0505\n","Epoch 3/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2ms/step - loss: 7.7594e-04 - mae: 0.0195 - val_loss: 0.0051 - val_mae: 0.0482\n","Epoch 4/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2ms/step - loss: 7.6891e-04 - mae: 0.0194 - val_loss: 0.0053 - val_mae: 0.0482\n","Epoch 5/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2ms/step - loss: 7.6646e-04 - mae: 0.0193 - val_loss: 0.0042 - val_mae: 0.0456\n","Epoch 6/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2ms/step - loss: 7.6648e-04 - mae: 0.0193 - val_loss: 0.0039 - val_mae: 0.0413\n","Epoch 7/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2ms/step - loss: 7.6198e-04 - mae: 0.0192 - val_loss: 0.0048 - val_mae: 0.0454\n","Epoch 8/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2ms/step - loss: 7.5792e-04 - mae: 0.0191 - val_loss: 0.0041 - val_mae: 0.0423\n","Epoch 9/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2ms/step - loss: 7.5357e-04 - mae: 0.0190 - val_loss: 0.0038 - val_mae: 0.0401\n","Epoch 10/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2ms/step - loss: 7.5446e-04 - mae: 0.0190 - val_loss: 0.0053 - val_mae: 0.0476\n","Epoch 11/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2ms/step - loss: 7.4986e-04 - mae: 0.0189 - val_loss: 0.0052 - val_mae: 0.0479\n","Epoch 12/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2ms/step - loss: 7.5027e-04 - mae: 0.0189 - val_loss: 0.0047 - val_mae: 0.0442\n","Epoch 13/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2ms/step - loss: 7.5313e-04 - mae: 0.0189 - val_loss: 0.0044 - val_mae: 0.0447\n","Epoch 14/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2ms/step - loss: 7.4882e-04 - mae: 0.0189 - val_loss: 0.0030 - val_mae: 0.0375\n","Epoch 15/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2ms/step - loss: 7.4724e-04 - mae: 0.0188 - val_loss: 0.0042 - val_mae: 0.0423\n","Epoch 16/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2ms/step - loss: 7.4596e-04 - mae: 0.0188 - val_loss: 0.0049 - val_mae: 0.0450\n","Epoch 17/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2ms/step - loss: 7.4800e-04 - mae: 0.0188 - val_loss: 0.0058 - val_mae: 0.0510\n","Epoch 18/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2ms/step - loss: 7.4520e-04 - mae: 0.0188 - val_loss: 0.0041 - val_mae: 0.0423\n","Epoch 19/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 3ms/step - loss: 7.4607e-04 - mae: 0.0188 - val_loss: 0.0038 - val_mae: 0.0400\n","Epoch 20/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2ms/step - loss: 7.4436e-04 - mae: 0.0188 - val_loss: 0.0051 - val_mae: 0.0466\n","Epoch 21/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 3ms/step - loss: 7.4494e-04 - mae: 0.0188 - val_loss: 0.0039 - val_mae: 0.0404\n","Epoch 22/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 3ms/step - loss: 7.4007e-04 - mae: 0.0187 - val_loss: 0.0049 - val_mae: 0.0457\n","Epoch 23/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2ms/step - loss: 7.4235e-04 - mae: 0.0188 - val_loss: 0.0036 - val_mae: 0.0402\n","Epoch 24/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2ms/step - loss: 7.4373e-04 - mae: 0.0188 - val_loss: 0.0047 - val_mae: 0.0458\n","\u001b[1m22185/22185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\n","📊 Resultados del modelo Transformer:\n","MAE  : 1.53 °C\n","RMSE : 2.22 °C\n","R²   : 0.919\n","✅ Modelo Transformer guardado como 'modelo_transformer_clima.h5'\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n","\n","🌤️ Predicciones de temperatura para las próximas 1 horas:\n","  +1h → 28.04 °C\n"]}]},{"cell_type":"code","source":["# =========================================\n","# Predicción de temperatura futura con LSTM (usando todas las columnas)\n","# =========================================\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","import joblib\n","import math\n","\n","# 1. Cargar datos\n","df = pd.read_csv(\"dataset_ml.csv\", sep=\";\", decimal=\".\", encoding=\"utf-8\", low_memory=False)\n","\n","# Limpiar nombres de columnas\n","df.columns = df.columns.str.strip()\n","\n","# 2. Procesar columna de tiempo\n","if 'momento' in df.columns:\n","    df['momento'] = pd.to_datetime(df['momento'], errors='coerce')\n","    df = df.dropna(subset=['momento'])\n","    df = df.sort_values('momento')\n","    cols = df.columns.drop('momento')\n","else:\n","    cols = df.columns\n","\n","# 3. Limpieza de datos\n","df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n","df = df.replace([np.inf, -np.inf], np.nan)\n","df[cols] = df[cols].apply(lambda x: np.where(np.abs(x) > 1e6, np.nan, x))\n","df = df.dropna()\n","\n","print(f\"✅ Datos limpios: {len(df)} filas\")\n","print(\"✅ Columnas utilizadas:\", list(cols))\n","\n","# 4. Escalado\n","scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(df[cols])\n","joblib.dump(scaler, \"scaler_clima.pkl\")\n","\n","# 5. Crear secuencias\n","def crear_secuencias(datos, n_pasos, columna_objetivo):\n","    X, y = [], []\n","    for i in range(n_pasos, len(datos)):\n","        X.append(datos[i - n_pasos:i])\n","        y.append(datos[i, columna_objetivo])\n","    return np.array(X), np.array(y)\n","\n","n_pasos = 24\n","columna_objetivo = list(cols).index('ts')\n","\n","X, y = crear_secuencias(scaled_data, n_pasos, columna_objetivo)\n","print(f\"📈 Secuencias creadas: X={X.shape}, y={y.shape}\")\n","\n","# 6. División train/test\n","n_train = int(len(X) * 0.8)\n","X_train, X_test = X[:n_train], X[n_train:]\n","y_train, y_test = y[:n_train], y[n_train:]\n","\n","# 7. Modelo LSTM\n","model = Sequential([\n","    LSTM(128, return_sequences=True, input_shape=(n_pasos, X.shape[2])),\n","    Dropout(0.2),\n","    LSTM(64),\n","    Dropout(0.2),\n","    Dense(1)\n","])\n","\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","# 8. Entrenamiento\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# 9. Evaluación\n","y_pred = model.predict(X_test)\n","mae = mean_absolute_error(y_test, y_pred)\n","rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n","r2 = r2_score(y_test, y_pred)\n","\n","print(\"\\n📊 MÉTRICAS DEL MODELO:\")\n","print(f\"MAE  = {mae:.4f}\")\n","print(f\"RMSE = {rmse:.4f}\")\n","print(f\"R²   = {r2:.4f}\")\n","\n","# 10. Predicción futura personalizada (1–6 horas)\n","try:\n","    horas_futuras = int(input(\"\\n⏱️ Ingresa cuántas horas hacia el futuro deseas predecir (1–6): \"))\n","except:\n","    horas_futuras = 6  # valor por defecto si el usuario no escribe bien\n","horas_futuras = max(1, min(6, horas_futuras))  # limitar entre 1 y 6\n","\n","ultima_secuencia = X[-1].copy()\n","predicciones_futuras = []\n","\n","for h in range(horas_futuras):\n","    prediccion_escalada = model.predict(ultima_secuencia.reshape(1, n_pasos, X.shape[2]))[0][0]\n","    predicciones_futuras.append(prediccion_escalada)\n","\n","    # Actualizar ventana (deslizar una hora)\n","    nueva_fila = ultima_secuencia[-1].copy()\n","    nueva_fila[columna_objetivo] = prediccion_escalada\n","    ultima_secuencia = np.vstack([ultima_secuencia[1:], nueva_fila])\n","\n","# 11. Invertir el escalado\n","dummy = np.zeros((len(predicciones_futuras), scaled_data.shape[1]))\n","dummy[:, columna_objetivo] = predicciones_futuras\n","predicciones_reales = scaler.inverse_transform(dummy)[:, columna_objetivo]\n","\n","print(f\"\\n🌡️ PREDICCIONES FUTURAS (próximas {horas_futuras} horas):\")\n","for i, temp in enumerate(predicciones_reales, start=1):\n","    print(f\"➡️ +{i}h: {temp:.2f} °C\")\n","\n","# 12. Guardar modelo y scaler\n","model.save(\"modelo_lstm_clima.h5\")\n","print(\"\\n✅ Modelo guardado como 'modelo_lstm_clima.h5'\")\n","print(\"✅ Scaler guardado como 'scaler_clima.pkl'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAHKelVFWt8o","executionInfo":{"status":"ok","timestamp":1760556243728,"user_tz":180,"elapsed":16347043,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"7f3e94a3-a0da-4ce0-b460-11ef768636ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Datos limpios: 3549541 filas\n","✅ Columnas utilizadas: ['ts', 'td', 'tMin12Horas', 'tMax12Horas', 'tMin24Horas', 'hr', 'p0', 'qfe1', 'qfe2', 'qff', 'qnh', 'tPromedio24h', 'deltaTemp1h', 'deltaPresion1h', 'humedadRelativaCambio']\n","📈 Secuencias creadas: X=(3549517, 24, 15), y=(3549517,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0524 - val_loss: 0.9370 - val_mae: 0.6098\n","Epoch 2/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m656s\u001b[0m 7ms/step - loss: 0.0044 - mae: 0.0452 - val_loss: 0.8574 - val_mae: 0.5664\n","Epoch 3/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m656s\u001b[0m 7ms/step - loss: 0.0042 - mae: 0.0444 - val_loss: 0.7791 - val_mae: 0.6011\n","Epoch 4/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0439 - val_loss: 0.4263 - val_mae: 0.3776\n","Epoch 5/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0436 - val_loss: 0.9551 - val_mae: 0.6201\n","Epoch 6/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0434 - val_loss: 2.6699 - val_mae: 1.0835\n","Epoch 7/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0433 - val_loss: 1.5962 - val_mae: 0.8012\n","Epoch 8/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0433 - val_loss: 0.6616 - val_mae: 0.4971\n","Epoch 9/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0533 - val_loss: 0.7898 - val_mae: 0.6050\n","Epoch 10/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m641s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0483 - val_loss: 0.4367 - val_mae: 0.4570\n","Epoch 11/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 7ms/step - loss: 0.0065 - mae: 0.0580 - val_loss: 0.8080 - val_mae: 0.6201\n","Epoch 12/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 7ms/step - loss: 0.0065 - mae: 0.0584 - val_loss: 0.7671 - val_mae: 0.6222\n","Epoch 13/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 7ms/step - loss: 0.0053 - mae: 0.0520 - val_loss: 0.4218 - val_mae: 0.4378\n","Epoch 14/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m641s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0494 - val_loss: 0.2621 - val_mae: 0.3271\n","Epoch 15/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0555 - val_loss: 0.1886 - val_mae: 0.2568\n","Epoch 16/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 7ms/step - loss: 0.0069 - mae: 0.0607 - val_loss: 0.5228 - val_mae: 0.4804\n","Epoch 17/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0663 - val_loss: 0.6824 - val_mae: 0.5298\n","Epoch 18/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0673 - val_loss: 0.6596 - val_mae: 0.5234\n","Epoch 19/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 7ms/step - loss: 0.0084 - mae: 0.0687 - val_loss: 0.5221 - val_mae: 0.4812\n","Epoch 20/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.0690 - val_loss: 1.2594 - val_mae: 0.7439\n","Epoch 21/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 7ms/step - loss: 0.0091 - mae: 0.0715 - val_loss: 1.8492 - val_mae: 0.8802\n","Epoch 22/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 7ms/step - loss: 0.0092 - mae: 0.0722 - val_loss: 1.6129 - val_mae: 0.8683\n","Epoch 23/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 7ms/step - loss: 0.0093 - mae: 0.0725 - val_loss: 0.8045 - val_mae: 0.6208\n","Epoch 24/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 7ms/step - loss: 0.0093 - mae: 0.0730 - val_loss: 1.0572 - val_mae: 0.6917\n","Epoch 25/100\n","\u001b[1m88738/88738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 7ms/step - loss: 0.0099 - mae: 0.0753 - val_loss: 0.5352 - val_mae: 0.5013\n","\u001b[1m22185/22185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2ms/step\n","\n","📊 MÉTRICAS DEL MODELO:\n","MAE  = 0.2568\n","RMSE = 0.4343\n","R²   = 0.8117\n","\n","⏱️ Ingresa cuántas horas hacia el futuro deseas predecir (1–6): 1\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\n","🌡️ PREDICCIONES FUTURAS (próximas 1 horas):\n","➡️ +1h: 30.93 °C\n","\n","✅ Modelo guardado como 'modelo_lstm_clima.h5'\n","✅ Scaler guardado como 'scaler_clima.pkl'\n"]}]}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 917951,
     "status": "ok",
     "timestamp": 1760361666371,
     "user": {
      "displayName": "Stefano Tabarroni",
      "userId": "07067172964849172747"
     },
     "user_tz": 180
    },
    "id": "-B1Pu_jtb4F5",
    "outputId": "feed7e8b-2a1b-4c91-e99a-605ca021959a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Columnas detectadas: Index(['momento', 'ts', 'td', 'tMin12Horas', 'tMax12Horas', 'tMin24Horas',\n",
      "       'hr', 'p0', 'qfe1', 'qfe2', 'qff', 'qnh', 'tPromedio24h', 'deltaTemp1h',\n",
      "       'deltaPresion1h', 'humedadRelativaCambio'],\n",
      "      dtype='object')\n",
      "ğŸ“Š Total de filas luego de limpiar: 96566\n",
      "âœ… Secuencias creadas: X=(96542, 24, 15), y=(96542,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - loss: 0.0238 - mae: 0.0956 - val_loss: 0.0025 - val_mae: 0.0431\n",
      "Epoch 2/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0594 - val_loss: 0.0012 - val_mae: 0.0272\n",
      "Epoch 3/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0575 - val_loss: 5.9358e-04 - val_mae: 0.0195\n",
      "Epoch 4/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0560 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 5/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0548 - val_loss: 9.9663e-04 - val_mae: 0.0248\n",
      "Epoch 6/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0540 - val_loss: 5.3553e-04 - val_mae: 0.0182\n",
      "Epoch 7/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0531 - val_loss: 0.0012 - val_mae: 0.0295\n",
      "Epoch 8/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0534 - val_loss: 8.5169e-04 - val_mae: 0.0223\n",
      "Epoch 9/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0535 - val_loss: 0.0011 - val_mae: 0.0278\n",
      "Epoch 10/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0054 - mae: 0.0530 - val_loss: 8.8176e-04 - val_mae: 0.0235\n",
      "Epoch 11/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0519 - val_loss: 6.2863e-04 - val_mae: 0.0204\n",
      "Epoch 12/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0518 - val_loss: 7.7966e-04 - val_mae: 0.0215\n",
      "Epoch 13/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0515 - val_loss: 4.0948e-04 - val_mae: 0.0157\n",
      "Epoch 14/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0520 - val_loss: 5.0372e-04 - val_mae: 0.0178\n",
      "Epoch 15/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0517 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 16/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 4.8706e-04 - val_mae: 0.0175\n",
      "Epoch 17/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0510 - val_loss: 9.7049e-04 - val_mae: 0.0263\n",
      "Epoch 18/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0505 - val_loss: 5.3425e-04 - val_mae: 0.0176\n",
      "Epoch 19/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 4.0031e-04 - val_mae: 0.0157\n",
      "Epoch 20/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 6.4248e-04 - val_mae: 0.0203\n",
      "Epoch 21/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0504 - val_loss: 0.0024 - val_mae: 0.0369\n",
      "Epoch 22/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 7.9020e-04 - val_mae: 0.0226\n",
      "Epoch 23/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 0.0013 - val_mae: 0.0290\n",
      "Epoch 24/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 4.6686e-04 - val_mae: 0.0166\n",
      "Epoch 25/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 8.1078e-04 - val_mae: 0.0228\n",
      "Epoch 26/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0497 - val_loss: 6.7848e-04 - val_mae: 0.0197\n",
      "Epoch 27/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 5.3024e-04 - val_mae: 0.0176\n",
      "Epoch 28/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.3657e-04 - val_mae: 0.0163\n",
      "Epoch 29/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 3.7822e-04 - val_mae: 0.0152\n",
      "Epoch 30/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 4.2350e-04 - val_mae: 0.0161\n",
      "Epoch 31/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 6.0196e-04 - val_mae: 0.0190\n",
      "Epoch 32/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0496 - val_loss: 8.4076e-04 - val_mae: 0.0228\n",
      "Epoch 33/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 4.8079e-04 - val_mae: 0.0166\n",
      "Epoch 34/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.7217e-04 - val_mae: 0.0172\n",
      "Epoch 35/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.0184e-04 - val_mae: 0.0159\n",
      "Epoch 36/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0487 - val_loss: 5.5092e-04 - val_mae: 0.0179\n",
      "Epoch 37/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 3.3302e-04 - val_mae: 0.0139\n",
      "Epoch 38/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 9.8238e-04 - val_mae: 0.0260\n",
      "Epoch 39/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.1797e-04 - val_mae: 0.0166\n",
      "Epoch 40/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0486 - val_loss: 6.4807e-04 - val_mae: 0.0205\n",
      "Epoch 41/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0487 - val_loss: 4.2618e-04 - val_mae: 0.0160\n",
      "Epoch 42/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0492 - val_loss: 5.1827e-04 - val_mae: 0.0182\n",
      "Epoch 43/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0489 - val_loss: 5.2594e-04 - val_mae: 0.0187\n",
      "Epoch 44/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 4.8642e-04 - val_mae: 0.0178\n",
      "Epoch 45/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0492 - val_loss: 4.6694e-04 - val_mae: 0.0171\n",
      "Epoch 46/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 3.4702e-04 - val_mae: 0.0147\n",
      "Epoch 47/100\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 3.9207e-04 - val_mae: 0.0155\n",
      "\u001b[1m604/604\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3.6404e-04 - mae: 0.0146\n",
      "ğŸ“‰ MAE en test: 0.01 Â°C\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ¡ï¸ Temperatura predicha a futuro: 14.09 Â°C\n",
      "âœ… Modelo guardado como 'modelo_lstm_clima.h5'\n",
      "âœ… Scaler guardado como 'scaler_clima.pkl'\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# PredicciÃ³n de temperatura futura con LSTM\n",
    "# =========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib\n",
    "\n",
    "# 1. Cargar datos correctamente\n",
    "df = pd.read_csv(\"dataset_ml.csv\", sep=\";\", decimal=\".\", encoding=\"utf-8\")\n",
    "\n",
    "# Quitar espacios extra en nombres de columnas\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(\"âœ… Columnas detectadas:\", df.columns)\n",
    "\n",
    "# 2. Procesar columna de tiempo si existe\n",
    "if 'momento' in df.columns:\n",
    "    df['momento'] = pd.to_datetime(df['momento'], errors='coerce')\n",
    "    cols = df.columns.drop('momento')\n",
    "else:\n",
    "    cols = df.columns\n",
    "\n",
    "# 3. Convertir a numÃ©rico y limpiar valores invÃ¡lidos\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Verificar cantidad de filas\n",
    "print(f\"ğŸ“Š Total de filas luego de limpiar: {len(df)}\")\n",
    "\n",
    "# 4. Escalado de todas las variables de entrada\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[cols])\n",
    "\n",
    "# Guardar scaler para uso futuro\n",
    "joblib.dump(scaler, \"scaler_clima.pkl\")\n",
    "\n",
    "# 5. Crear secuencias de tiempo\n",
    "def crear_secuencias(datos, n_pasos, columna_objetivo):\n",
    "    X, y = [], []\n",
    "    for i in range(n_pasos, len(datos)):\n",
    "        X.append(datos[i - n_pasos:i])\n",
    "        y.append(datos[i, columna_objetivo])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Usaremos 24 pasos (por ejemplo, 24 horas si los datos son horarios)\n",
    "n_pasos = 24\n",
    "# Buscar el Ã­ndice de la columna 'ts' (temperatura) en el escalado\n",
    "columna_objetivo = list(cols).index('ts')\n",
    "\n",
    "X, y = crear_secuencias(scaled_data, n_pasos, columna_objetivo)\n",
    "\n",
    "print(f\"âœ… Secuencias creadas: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "# 6. Dividir en entrenamiento y test\n",
    "porc_entrenamiento = 0.8\n",
    "n_train = int(len(X) * porc_entrenamiento)\n",
    "\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "# 7. ConstrucciÃ³n del modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(n_pasos, X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))  # salida: temperatura futura\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# 8. Entrenamiento\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 9. EvaluaciÃ³n del modelo\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"ğŸ“‰ MAE en test: {mae:.2f} Â°C\")\n",
    "\n",
    "# 10. PredicciÃ³n futura usando la Ãºltima ventana\n",
    "ultima_secuencia = X[-1].reshape(1, n_pasos, X.shape[2])\n",
    "prediccion_escalada = model.predict(ultima_secuencia)[0][0]\n",
    "\n",
    "# 11. Invertir el escalado para obtener la temperatura real\n",
    "dummy = np.zeros((1, scaled_data.shape[1]))\n",
    "dummy[0, columna_objetivo] = prediccion_escalada\n",
    "prediccion_real = scaler.inverse_transform(dummy)[0, columna_objetivo]\n",
    "\n",
    "print(f\"ğŸŒ¡ï¸ Temperatura predicha a futuro: {prediccion_real:.2f} Â°C\")\n",
    "\n",
    "# 12. Guardar modelo y scaler\n",
    "model.save(\"modelo_lstm_clima.h5\")\n",
    "print(\"âœ… Modelo guardado como 'modelo_lstm_clima.h5'\")\n",
    "print(\"âœ… Scaler guardado como 'scaler_clima.pkl'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPwYWG9QnDWzKoj6rDdb13Z",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPwYWG9QnDWzKoj6rDdb13Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-B1Pu_jtb4F5","executionInfo":{"status":"ok","timestamp":1760361666371,"user_tz":180,"elapsed":917951,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"feed7e8b-2a1b-4c91-e99a-605ca021959a"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Columnas detectadas: Index(['momento', 'ts', 'td', 'tMin12Horas', 'tMax12Horas', 'tMin24Horas',\n","       'hr', 'p0', 'qfe1', 'qfe2', 'qff', 'qnh', 'tPromedio24h', 'deltaTemp1h',\n","       'deltaPresion1h', 'humedadRelativaCambio'],\n","      dtype='object')\n","ğŸ“Š Total de filas luego de limpiar: 96566\n","âœ… Secuencias creadas: X=(96542, 24, 15), y=(96542,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - loss: 0.0238 - mae: 0.0956 - val_loss: 0.0025 - val_mae: 0.0431\n","Epoch 2/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0594 - val_loss: 0.0012 - val_mae: 0.0272\n","Epoch 3/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0575 - val_loss: 5.9358e-04 - val_mae: 0.0195\n","Epoch 4/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0560 - val_loss: 0.0017 - val_mae: 0.0325\n","Epoch 5/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0548 - val_loss: 9.9663e-04 - val_mae: 0.0248\n","Epoch 6/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0540 - val_loss: 5.3553e-04 - val_mae: 0.0182\n","Epoch 7/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0531 - val_loss: 0.0012 - val_mae: 0.0295\n","Epoch 8/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0534 - val_loss: 8.5169e-04 - val_mae: 0.0223\n","Epoch 9/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0535 - val_loss: 0.0011 - val_mae: 0.0278\n","Epoch 10/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0054 - mae: 0.0530 - val_loss: 8.8176e-04 - val_mae: 0.0235\n","Epoch 11/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0519 - val_loss: 6.2863e-04 - val_mae: 0.0204\n","Epoch 12/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0518 - val_loss: 7.7966e-04 - val_mae: 0.0215\n","Epoch 13/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0515 - val_loss: 4.0948e-04 - val_mae: 0.0157\n","Epoch 14/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0520 - val_loss: 5.0372e-04 - val_mae: 0.0178\n","Epoch 15/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0517 - val_loss: 0.0013 - val_mae: 0.0271\n","Epoch 16/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 4.8706e-04 - val_mae: 0.0175\n","Epoch 17/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0510 - val_loss: 9.7049e-04 - val_mae: 0.0263\n","Epoch 18/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0505 - val_loss: 5.3425e-04 - val_mae: 0.0176\n","Epoch 19/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 4.0031e-04 - val_mae: 0.0157\n","Epoch 20/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 6.4248e-04 - val_mae: 0.0203\n","Epoch 21/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0504 - val_loss: 0.0024 - val_mae: 0.0369\n","Epoch 22/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 7.9020e-04 - val_mae: 0.0226\n","Epoch 23/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 0.0013 - val_mae: 0.0290\n","Epoch 24/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 4.6686e-04 - val_mae: 0.0166\n","Epoch 25/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 8.1078e-04 - val_mae: 0.0228\n","Epoch 26/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0497 - val_loss: 6.7848e-04 - val_mae: 0.0197\n","Epoch 27/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 5.3024e-04 - val_mae: 0.0176\n","Epoch 28/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.3657e-04 - val_mae: 0.0163\n","Epoch 29/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 3.7822e-04 - val_mae: 0.0152\n","Epoch 30/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 4.2350e-04 - val_mae: 0.0161\n","Epoch 31/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 6.0196e-04 - val_mae: 0.0190\n","Epoch 32/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0496 - val_loss: 8.4076e-04 - val_mae: 0.0228\n","Epoch 33/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 4.8079e-04 - val_mae: 0.0166\n","Epoch 34/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.7217e-04 - val_mae: 0.0172\n","Epoch 35/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.0184e-04 - val_mae: 0.0159\n","Epoch 36/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0487 - val_loss: 5.5092e-04 - val_mae: 0.0179\n","Epoch 37/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 3.3302e-04 - val_mae: 0.0139\n","Epoch 38/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 9.8238e-04 - val_mae: 0.0260\n","Epoch 39/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 4.1797e-04 - val_mae: 0.0166\n","Epoch 40/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0486 - val_loss: 6.4807e-04 - val_mae: 0.0205\n","Epoch 41/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0487 - val_loss: 4.2618e-04 - val_mae: 0.0160\n","Epoch 42/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0492 - val_loss: 5.1827e-04 - val_mae: 0.0182\n","Epoch 43/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0489 - val_loss: 5.2594e-04 - val_mae: 0.0187\n","Epoch 44/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 4.8642e-04 - val_mae: 0.0178\n","Epoch 45/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0492 - val_loss: 4.6694e-04 - val_mae: 0.0171\n","Epoch 46/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 3.4702e-04 - val_mae: 0.0147\n","Epoch 47/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 3.9207e-04 - val_mae: 0.0155\n","\u001b[1m604/604\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3.6404e-04 - mae: 0.0146\n","ğŸ“‰ MAE en test: 0.01 Â°C\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["ğŸŒ¡ï¸ Temperatura predicha a futuro: 14.09 Â°C\n","âœ… Modelo guardado como 'modelo_lstm_clima.h5'\n","âœ… Scaler guardado como 'scaler_clima.pkl'\n"]}],"source":["# =========================================\n","# PredicciÃ³n de temperatura futura con LSTM\n","# =========================================\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","import joblib\n","\n","# 1. Cargar datos correctamente\n","df = pd.read_csv(\"dataset_ml.csv\", sep=\";\", decimal=\".\", encoding=\"utf-8\")\n","\n","# Quitar espacios extra en nombres de columnas\n","df.columns = df.columns.str.strip()\n","\n","print(\"âœ… Columnas detectadas:\", df.columns)\n","\n","# 2. Procesar columna de tiempo si existe\n","if 'momento' in df.columns:\n","    df['momento'] = pd.to_datetime(df['momento'], errors='coerce')\n","    cols = df.columns.drop('momento')\n","else:\n","    cols = df.columns\n","\n","# 3. Convertir a numÃ©rico y limpiar valores invÃ¡lidos\n","df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n","df = df.replace([np.inf, -np.inf], np.nan).dropna()\n","\n","# Verificar cantidad de filas\n","print(f\"ğŸ“Š Total de filas luego de limpiar: {len(df)}\")\n","\n","# 4. Escalado de todas las variables de entrada\n","scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(df[cols])\n","\n","# Guardar scaler para uso futuro\n","joblib.dump(scaler, \"scaler_clima.pkl\")\n","\n","# 5. Crear secuencias de tiempo\n","def crear_secuencias(datos, n_pasos, columna_objetivo):\n","    X, y = [], []\n","    for i in range(n_pasos, len(datos)):\n","        X.append(datos[i - n_pasos:i])\n","        y.append(datos[i, columna_objetivo])\n","    return np.array(X), np.array(y)\n","\n","# Usaremos 24 pasos (por ejemplo, 24 horas si los datos son horarios)\n","n_pasos = 24\n","# Buscar el Ã­ndice de la columna 'ts' (temperatura) en el escalado\n","columna_objetivo = list(cols).index('ts')\n","\n","X, y = crear_secuencias(scaled_data, n_pasos, columna_objetivo)\n","\n","print(f\"âœ… Secuencias creadas: X={X.shape}, y={y.shape}\")\n","\n","# 6. Dividir en entrenamiento y test\n","porc_entrenamiento = 0.8\n","n_train = int(len(X) * porc_entrenamiento)\n","\n","X_train, X_test = X[:n_train], X[n_train:]\n","y_train, y_test = y[:n_train], y[n_train:]\n","\n","# 7. ConstrucciÃ³n del modelo LSTM\n","model = Sequential()\n","model.add(LSTM(128, return_sequences=True, input_shape=(n_pasos, X.shape[2])))\n","model.add(Dropout(0.2))\n","model.add(LSTM(64))\n","model.add(Dropout(0.2))\n","model.add(Dense(1))  # salida: temperatura futura\n","\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","# 8. Entrenamiento\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# 9. EvaluaciÃ³n del modelo\n","loss, mae = model.evaluate(X_test, y_test)\n","print(f\"ğŸ“‰ MAE en test: {mae:.2f} Â°C\")\n","\n","# 10. PredicciÃ³n futura usando la Ãºltima ventana\n","ultima_secuencia = X[-1].reshape(1, n_pasos, X.shape[2])\n","prediccion_escalada = model.predict(ultima_secuencia)[0][0]\n","\n","# 11. Invertir el escalado para obtener la temperatura real\n","dummy = np.zeros((1, scaled_data.shape[1]))\n","dummy[0, columna_objetivo] = prediccion_escalada\n","prediccion_real = scaler.inverse_transform(dummy)[0, columna_objetivo]\n","\n","print(f\"ğŸŒ¡ï¸ Temperatura predicha a futuro: {prediccion_real:.2f} Â°C\")\n","\n","# 12. Guardar modelo y scaler\n","model.save(\"modelo_lstm_clima.h5\")\n","print(\"âœ… Modelo guardado como 'modelo_lstm_clima.h5'\")\n","print(\"âœ… Scaler guardado como 'scaler_clima.pkl'\")\n","\n"]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAwL7bM4gOjb","executionInfo":{"status":"ok","timestamp":1760358061091,"user_tz":180,"elapsed":45577,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"ad711f79-b3ae-4837-8062-de6604df634d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow\n","  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Collecting astunparse>=1.6.0 (from tensorflow)\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n","Collecting flatbuffers>=24.3.25 (from tensorflow)\n","  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n","Collecting google_pasta>=0.1.1 (from tensorflow)\n","  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n","Collecting libclang>=13.0.0 (from tensorflow)\n","  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.32.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n","Collecting tensorboard~=2.20.0 (from tensorflow)\n","  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n","Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n","  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n","  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n","Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n","  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n","Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m716.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n","Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m135.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorboard-data-server, google_pasta, tensorboard, astunparse, tensorflow\n","Successfully installed astunparse-1.6.3 flatbuffers-25.9.23 google_pasta-0.2.0 libclang-18.1.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 werkzeug-3.1.3 wheel-0.45.1\n"]}]},{"cell_type":"code","source":["# =========================================\n","# PredicciÃ³n de temperatura futura con GRU\n","# =========================================\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","model_gru = Sequential()\n","model_gru.add(GRU(128, return_sequences=True, input_shape=(n_pasos, X.shape[2])))\n","model_gru.add(Dropout(0.2))\n","model_gru.add(GRU(64))\n","model_gru.add(Dropout(0.2))\n","model_gru.add(Dense(1))\n","\n","model_gru.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history_gru = model_gru.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","loss_gru, mae_gru = model_gru.evaluate(X_test, y_test)\n","print(f\"ğŸ“‰ MAE GRU: {mae_gru:.2f} Â°C\")\n","\n","model_gru.save(\"modelo_gru_clima.h5\")\n","print(\"âœ… Modelo GRU guardado como 'modelo_gru_clima.h5'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHJGWN4Yzqjn","executionInfo":{"status":"ok","timestamp":1760363627476,"user_tz":180,"elapsed":670962,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"bddb4e78-749e-4e65-c09d-8941464eb0c3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0242 - mae: 0.1005 - val_loss: 0.0028 - val_mae: 0.0449\n","Epoch 2/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0066 - mae: 0.0595 - val_loss: 0.0010 - val_mae: 0.0247\n","Epoch 3/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0557 - val_loss: 9.8220e-04 - val_mae: 0.0251\n","Epoch 4/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0548 - val_loss: 9.9329e-04 - val_mae: 0.0256\n","Epoch 5/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0054 - mae: 0.0533 - val_loss: 9.4119e-04 - val_mae: 0.0241\n","Epoch 6/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0052 - mae: 0.0525 - val_loss: 6.2185e-04 - val_mae: 0.0201\n","Epoch 7/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0052 - mae: 0.0521 - val_loss: 9.3193e-04 - val_mae: 0.0241\n","Epoch 8/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0053 - mae: 0.0527 - val_loss: 5.6385e-04 - val_mae: 0.0184\n","Epoch 9/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0515 - val_loss: 6.7713e-04 - val_mae: 0.0209\n","Epoch 10/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0051 - mae: 0.0518 - val_loss: 7.6166e-04 - val_mae: 0.0214\n","Epoch 11/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0517 - val_loss: 0.0014 - val_mae: 0.0287\n","Epoch 12/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0051 - mae: 0.0517 - val_loss: 5.1327e-04 - val_mae: 0.0172\n","Epoch 13/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0515 - val_loss: 0.0011 - val_mae: 0.0280\n","Epoch 14/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0510 - val_loss: 4.6160e-04 - val_mae: 0.0167\n","Epoch 15/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0510 - val_loss: 7.2458e-04 - val_mae: 0.0214\n","Epoch 16/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0512 - val_loss: 4.7069e-04 - val_mae: 0.0174\n","Epoch 17/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 7.6032e-04 - val_mae: 0.0217\n","Epoch 18/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0508 - val_loss: 8.0615e-04 - val_mae: 0.0223\n","Epoch 19/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0508 - val_loss: 0.0012 - val_mae: 0.0281\n","Epoch 20/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0509 - val_loss: 4.4430e-04 - val_mae: 0.0168\n","Epoch 21/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 5.6714e-04 - val_mae: 0.0186\n","Epoch 22/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0506 - val_loss: 4.5732e-04 - val_mae: 0.0170\n","Epoch 23/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 4.8388e-04 - val_mae: 0.0177\n","Epoch 24/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0504 - val_loss: 5.2879e-04 - val_mae: 0.0181\n","Epoch 25/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 4.3041e-04 - val_mae: 0.0163\n","Epoch 26/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 5.0258e-04 - val_mae: 0.0178\n","Epoch 27/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0496 - val_loss: 3.4072e-04 - val_mae: 0.0145\n","Epoch 28/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0501 - val_loss: 4.0771e-04 - val_mae: 0.0157\n","Epoch 29/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0505 - val_loss: 6.4684e-04 - val_mae: 0.0207\n","Epoch 30/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0495 - val_loss: 3.6565e-04 - val_mae: 0.0149\n","Epoch 31/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0500 - val_loss: 4.4089e-04 - val_mae: 0.0165\n","Epoch 32/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 3.6654e-04 - val_mae: 0.0150\n","Epoch 33/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 0.0010 - val_mae: 0.0255\n","Epoch 34/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0501 - val_loss: 0.0011 - val_mae: 0.0275\n","Epoch 35/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 9.3592e-04 - val_mae: 0.0256\n","Epoch 36/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 4.7378e-04 - val_mae: 0.0177\n","Epoch 37/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0496 - val_loss: 5.3415e-04 - val_mae: 0.0187\n","\u001b[1m604/604\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3.4524e-04 - mae: 0.0146\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["ğŸ“‰ MAE GRU: 0.01 Â°C\n","âœ… Modelo GRU guardado como 'modelo_gru_clima.h5'\n"]}]},{"cell_type":"code","source":["# =========================================\n","# Modelo hÃ­brido CNN + LSTM\n","# =========================================\n","\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n","\n","model_cnn_lstm = Sequential()\n","model_cnn_lstm.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_pasos, X.shape[2])))\n","model_cnn_lstm.add(MaxPooling1D(pool_size=2))\n","model_cnn_lstm.add(LSTM(64))\n","model_cnn_lstm.add(Dropout(0.3))\n","model_cnn_lstm.add(Dense(1))\n","\n","model_cnn_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history_cnnlstm = model_cnn_lstm.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","loss_cnnlstm, mae_cnnlstm = model_cnn_lstm.evaluate(X_test, y_test)\n","print(f\"ğŸ“‰ MAE CNN+LSTM: {mae_cnnlstm:.2f} Â°C\")\n","\n","model_cnn_lstm.save(\"modelo_cnn_lstm_clima.h5\")\n","print(\"âœ… Modelo CNN+LSTM guardado como 'modelo_cnn_lstm_clima.h5'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APCwB7BOz_MX","executionInfo":{"status":"ok","timestamp":1760364114823,"user_tz":180,"elapsed":469605,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"e529f261-d4cf-456c-89af-80fa922427e9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.0360 - mae: 0.1170 - val_loss: 0.0017 - val_mae: 0.0326\n","Epoch 2/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0711 - val_loss: 0.0027 - val_mae: 0.0414\n","Epoch 3/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0092 - mae: 0.0693 - val_loss: 0.0013 - val_mae: 0.0278\n","Epoch 4/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0677 - val_loss: 0.0012 - val_mae: 0.0266\n","Epoch 5/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0083 - mae: 0.0658 - val_loss: 0.0019 - val_mae: 0.0329\n","Epoch 6/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0083 - mae: 0.0657 - val_loss: 0.0014 - val_mae: 0.0314\n","Epoch 7/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0083 - mae: 0.0651 - val_loss: 8.9853e-04 - val_mae: 0.0229\n","Epoch 8/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0080 - mae: 0.0642 - val_loss: 7.8389e-04 - val_mae: 0.0215\n","Epoch 9/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0080 - mae: 0.0635 - val_loss: 0.0014 - val_mae: 0.0291\n","Epoch 10/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0080 - mae: 0.0637 - val_loss: 9.1042e-04 - val_mae: 0.0231\n","Epoch 11/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0080 - mae: 0.0639 - val_loss: 0.0019 - val_mae: 0.0355\n","Epoch 12/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0632 - val_loss: 6.5339e-04 - val_mae: 0.0200\n","Epoch 13/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0633 - val_loss: 8.9072e-04 - val_mae: 0.0240\n","Epoch 14/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0079 - mae: 0.0634 - val_loss: 0.0017 - val_mae: 0.0351\n","Epoch 15/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0630 - val_loss: 7.7469e-04 - val_mae: 0.0224\n","Epoch 16/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0629 - val_loss: 6.2864e-04 - val_mae: 0.0199\n","Epoch 17/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0626 - val_loss: 6.8077e-04 - val_mae: 0.0201\n","Epoch 18/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0630 - val_loss: 6.5330e-04 - val_mae: 0.0200\n","Epoch 19/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0627 - val_loss: 5.7951e-04 - val_mae: 0.0188\n","Epoch 20/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0623 - val_loss: 9.4914e-04 - val_mae: 0.0249\n","Epoch 21/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0629 - val_loss: 5.2909e-04 - val_mae: 0.0180\n","Epoch 22/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0075 - mae: 0.0618 - val_loss: 7.8096e-04 - val_mae: 0.0216\n","Epoch 23/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0622 - val_loss: 7.5798e-04 - val_mae: 0.0228\n","Epoch 24/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0618 - val_loss: 7.7391e-04 - val_mae: 0.0226\n","Epoch 25/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.0077 - mae: 0.0625 - val_loss: 0.0023 - val_mae: 0.0404\n","Epoch 26/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0621 - val_loss: 8.1744e-04 - val_mae: 0.0227\n","Epoch 27/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0621 - val_loss: 0.0011 - val_mae: 0.0256\n","Epoch 28/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0622 - val_loss: 0.0018 - val_mae: 0.0359\n","Epoch 29/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0622 - val_loss: 5.5535e-04 - val_mae: 0.0185\n","Epoch 30/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0623 - val_loss: 0.0010 - val_mae: 0.0262\n","Epoch 31/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0619 - val_loss: 0.0013 - val_mae: 0.0288\n","\u001b[1m604/604\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.6212e-04 - mae: 0.0185\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["ğŸ“‰ MAE CNN+LSTM: 0.02 Â°C\n","âœ… Modelo CNN+LSTM guardado como 'modelo_cnn_lstm_clima.h5'\n"]}]},{"cell_type":"code","source":["# =========================================\n","# Modelo basado en Transformer simple\n","# =========================================\n","\n","from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Flatten\n","import tensorflow as tf\n","inputs = tf.keras.Input(shape=(n_pasos, X.shape[2]))\n","x = MultiHeadAttention(num_heads=4, key_dim=16)(inputs, inputs)\n","x = LayerNormalization(epsilon=1e-6)(x)\n","x = Flatten()(x)\n","x = Dense(64, activation='relu')(x)\n","x = Dropout(0.3)(x)\n","outputs = Dense(1)(x)\n","\n","model_transformer = tf.keras.Model(inputs, outputs)\n","model_transformer.compile(optimizer=Adam(0.001), loss='mse', metrics=['mae'])\n","\n","history_trans = model_transformer.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","loss_trans, mae_trans = model_transformer.evaluate(X_test, y_test)\n","print(f\"ğŸ“‰ MAE Transformer: {mae_trans:.2f} Â°C\")\n","\n","model_transformer.save(\"modelo_transformer_clima.h5\")\n","print(\"âœ… Modelo Transformer guardado como 'modelo_transformer_clima.h5'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBVh8f6h0AT2","executionInfo":{"status":"ok","timestamp":1760366561747,"user_tz":180,"elapsed":239753,"user":{"displayName":"Stefano Tabarroni","userId":"07067172964849172747"}},"outputId":"234c14fc-c0d3-43ce-d897-96bc1032a7db"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1362 - mae: 0.2151 - val_loss: 0.0280 - val_mae: 0.1340\n","Epoch 2/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0300 - mae: 0.1266 - val_loss: 0.0097 - val_mae: 0.0763\n","Epoch 3/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0273 - mae: 0.1207 - val_loss: 0.0057 - val_mae: 0.0601\n","Epoch 4/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0262 - mae: 0.1183 - val_loss: 0.0035 - val_mae: 0.0486\n","Epoch 5/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0255 - mae: 0.1160 - val_loss: 0.0038 - val_mae: 0.0494\n","Epoch 6/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0248 - mae: 0.1139 - val_loss: 0.0076 - val_mae: 0.0694\n","Epoch 7/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0245 - mae: 0.1131 - val_loss: 0.0067 - val_mae: 0.0655\n","Epoch 8/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0239 - mae: 0.1108 - val_loss: 0.0049 - val_mae: 0.0591\n","Epoch 9/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0233 - mae: 0.1100 - val_loss: 0.0102 - val_mae: 0.0826\n","Epoch 10/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0236 - mae: 0.1098 - val_loss: 0.0046 - val_mae: 0.0560\n","Epoch 11/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0231 - mae: 0.1090 - val_loss: 0.0021 - val_mae: 0.0359\n","Epoch 12/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0224 - mae: 0.1068 - val_loss: 0.0039 - val_mae: 0.0515\n","Epoch 13/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0214 - mae: 0.1042 - val_loss: 0.0014 - val_mae: 0.0290\n","Epoch 14/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0212 - mae: 0.1033 - val_loss: 0.0014 - val_mae: 0.0298\n","Epoch 15/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0188 - mae: 0.0979 - val_loss: 0.0018 - val_mae: 0.0337\n","Epoch 16/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0176 - mae: 0.0948 - val_loss: 0.0051 - val_mae: 0.0571\n","Epoch 17/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.0912 - val_loss: 0.0031 - val_mae: 0.0476\n","Epoch 18/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0162 - mae: 0.0906 - val_loss: 0.0051 - val_mae: 0.0576\n","Epoch 19/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0164 - mae: 0.0909 - val_loss: 0.0033 - val_mae: 0.0476\n","Epoch 20/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0164 - mae: 0.0908 - val_loss: 9.9910e-04 - val_mae: 0.0244\n","Epoch 21/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.0913 - val_loss: 0.0018 - val_mae: 0.0344\n","Epoch 22/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0166 - mae: 0.0915 - val_loss: 0.0021 - val_mae: 0.0378\n","Epoch 23/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0162 - mae: 0.0897 - val_loss: 0.0012 - val_mae: 0.0270\n","Epoch 24/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0155 - mae: 0.0884 - val_loss: 0.0053 - val_mae: 0.0632\n","Epoch 25/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0896 - val_loss: 0.0020 - val_mae: 0.0347\n","Epoch 26/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0156 - mae: 0.0886 - val_loss: 0.0035 - val_mae: 0.0487\n","Epoch 27/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0896 - val_loss: 0.0013 - val_mae: 0.0287\n","Epoch 28/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0897 - val_loss: 0.0070 - val_mae: 0.0782\n","Epoch 29/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0154 - mae: 0.0882 - val_loss: 0.0011 - val_mae: 0.0254\n","Epoch 30/100\n","\u001b[1m2414/2414\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0158 - mae: 0.0889 - val_loss: 0.0029 - val_mae: 0.0405\n","\u001b[1m604/604\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0251\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["ğŸ“‰ MAE Transformer: 0.02 Â°C\n","âœ… Modelo Transformer guardado como 'modelo_transformer_clima.h5'\n"]}]}]}